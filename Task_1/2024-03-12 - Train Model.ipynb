{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 19:49:52.070033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import L2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.params import params\n",
    "\n",
    "embedding_dim = params['embedding_dim']\n",
    "window_size = params['window_size']\n",
    "min_count = params['min_count']\n",
    "\n",
    "filepath_in = 'data/sample_data_for_task1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_in)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# We have imbalanced data so we sample the same amount from each class\n",
    "df_list = []\n",
    "\n",
    "for sub in df['label'].unique():\n",
    "    df_temp = df[df['label'] == sub]\n",
    "    for i in range(3):\n",
    "        df_list.append(df_temp.sample(2500))\n",
    "\n",
    "df_new = pd.concat(df_list)\n",
    "\n",
    "X = df_new['text'].reset_index().drop(columns='index')\n",
    "y = df_new['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Label Encoder\n",
    "with open('utils/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "tokenized_text = X_train['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utils/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_text, \n",
    "    vector_size=embedding_dim, \n",
    "    window=window_size, \n",
    "    min_count=min_count\n",
    ")\n",
    "\n",
    "word2vec_model.save('utils/word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embeddings(text, word2vec_model=word2vec_model):\n",
    "    tokens = tokenizer(text)\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in word2vec_model.wv:\n",
    "            embeddings.append(word2vec_model.wv[token])\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  # Average of word embeddings in the text\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)  # If no embeddings found, return zero vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_df(df_in):\n",
    "    df = df_in.copy()\n",
    "    df['embeddings'] = df['text'].apply(text_to_embeddings)\n",
    "    col_list = [f'emb_{i}' for i in range(embedding_dim)]\n",
    "    df[col_list] = pd.DataFrame(df['embeddings'].tolist(), index= df.index)\n",
    "    df = df.drop(columns=['text', 'embeddings'])\n",
    "    return df\n",
    "\n",
    "X_train = embed_df(X_train)\n",
    "X_test = embed_df(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(64, activation='relu', bias_regularizer=L2(1e-3), activity_regularizer=L2(1e-3)))  # Hidden layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu', bias_regularizer=L2(1e-3), activity_regularizer=L2(1e-3)))  # Hidden layer\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 1.6162 - accuracy: 0.3022 - val_loss: 1.5220 - val_accuracy: 0.3401\n",
      "Epoch 2/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.5017 - accuracy: 0.3533 - val_loss: 1.4897 - val_accuracy: 0.3728\n",
      "Epoch 3/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.4748 - accuracy: 0.3713 - val_loss: 1.4631 - val_accuracy: 0.3815\n",
      "Epoch 4/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.4523 - accuracy: 0.3831 - val_loss: 1.4506 - val_accuracy: 0.3840\n",
      "Epoch 5/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.4358 - accuracy: 0.3951 - val_loss: 1.4332 - val_accuracy: 0.4028\n",
      "Epoch 6/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.4163 - accuracy: 0.4083 - val_loss: 1.4350 - val_accuracy: 0.4011\n",
      "Epoch 7/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3977 - accuracy: 0.4228 - val_loss: 1.3893 - val_accuracy: 0.4354\n",
      "Epoch 8/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3796 - accuracy: 0.4374 - val_loss: 1.3723 - val_accuracy: 0.4433\n",
      "Epoch 9/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3601 - accuracy: 0.4442 - val_loss: 1.3577 - val_accuracy: 0.4492\n",
      "Epoch 10/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3458 - accuracy: 0.4500 - val_loss: 1.3430 - val_accuracy: 0.4610\n",
      "Epoch 11/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3314 - accuracy: 0.4579 - val_loss: 1.3555 - val_accuracy: 0.4408\n",
      "Epoch 12/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3179 - accuracy: 0.4672 - val_loss: 1.3325 - val_accuracy: 0.4632\n",
      "Epoch 13/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.3078 - accuracy: 0.4692 - val_loss: 1.3169 - val_accuracy: 0.4628\n",
      "Epoch 14/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2996 - accuracy: 0.4713 - val_loss: 1.3078 - val_accuracy: 0.4696\n",
      "Epoch 15/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2930 - accuracy: 0.4790 - val_loss: 1.3052 - val_accuracy: 0.4686\n",
      "Epoch 16/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2823 - accuracy: 0.4825 - val_loss: 1.2957 - val_accuracy: 0.4706\n",
      "Epoch 17/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2741 - accuracy: 0.4838 - val_loss: 1.2923 - val_accuracy: 0.4815\n",
      "Epoch 18/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2661 - accuracy: 0.4886 - val_loss: 1.2987 - val_accuracy: 0.4737\n",
      "Epoch 19/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2593 - accuracy: 0.4910 - val_loss: 1.3474 - val_accuracy: 0.4529\n",
      "Epoch 20/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2514 - accuracy: 0.4970 - val_loss: 1.2708 - val_accuracy: 0.4861\n",
      "Epoch 21/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2442 - accuracy: 0.5002 - val_loss: 1.2747 - val_accuracy: 0.4812\n",
      "Epoch 22/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2392 - accuracy: 0.5043 - val_loss: 1.2713 - val_accuracy: 0.4799\n",
      "Epoch 23/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2295 - accuracy: 0.5090 - val_loss: 1.2592 - val_accuracy: 0.4958\n",
      "Epoch 24/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2244 - accuracy: 0.5066 - val_loss: 1.2521 - val_accuracy: 0.5006\n",
      "Epoch 25/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2222 - accuracy: 0.5116 - val_loss: 1.2568 - val_accuracy: 0.4921\n",
      "Epoch 26/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2146 - accuracy: 0.5163 - val_loss: 1.2715 - val_accuracy: 0.4875\n",
      "Epoch 27/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2097 - accuracy: 0.5177 - val_loss: 1.2322 - val_accuracy: 0.5061\n",
      "Epoch 28/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.2039 - accuracy: 0.5198 - val_loss: 1.2448 - val_accuracy: 0.5031\n",
      "Epoch 29/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1957 - accuracy: 0.5252 - val_loss: 1.2329 - val_accuracy: 0.5096\n",
      "Epoch 30/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1928 - accuracy: 0.5267 - val_loss: 1.2080 - val_accuracy: 0.5190\n",
      "Epoch 31/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1863 - accuracy: 0.5309 - val_loss: 1.2217 - val_accuracy: 0.5132\n",
      "Epoch 32/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1823 - accuracy: 0.5318 - val_loss: 1.2246 - val_accuracy: 0.5176\n",
      "Epoch 33/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1804 - accuracy: 0.5338 - val_loss: 1.2166 - val_accuracy: 0.5125\n",
      "Epoch 34/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1727 - accuracy: 0.5365 - val_loss: 1.2107 - val_accuracy: 0.5203\n",
      "Epoch 35/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1643 - accuracy: 0.5404 - val_loss: 1.2293 - val_accuracy: 0.5090\n",
      "Epoch 36/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1624 - accuracy: 0.5432 - val_loss: 1.2257 - val_accuracy: 0.5125\n",
      "Epoch 37/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1611 - accuracy: 0.5401 - val_loss: 1.2103 - val_accuracy: 0.5178\n",
      "Epoch 38/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1527 - accuracy: 0.5439 - val_loss: 1.1964 - val_accuracy: 0.5268\n",
      "Epoch 39/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1476 - accuracy: 0.5478 - val_loss: 1.1885 - val_accuracy: 0.5243\n",
      "Epoch 40/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1443 - accuracy: 0.5489 - val_loss: 1.1850 - val_accuracy: 0.5342\n",
      "Epoch 41/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1412 - accuracy: 0.5492 - val_loss: 1.1751 - val_accuracy: 0.5386\n",
      "Epoch 42/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1366 - accuracy: 0.5528 - val_loss: 1.1647 - val_accuracy: 0.5365\n",
      "Epoch 43/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1335 - accuracy: 0.5561 - val_loss: 1.1846 - val_accuracy: 0.5337\n",
      "Epoch 44/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1263 - accuracy: 0.5593 - val_loss: 1.1699 - val_accuracy: 0.5365\n",
      "Epoch 45/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1196 - accuracy: 0.5600 - val_loss: 1.1976 - val_accuracy: 0.5224\n",
      "Epoch 46/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1188 - accuracy: 0.5628 - val_loss: 1.1661 - val_accuracy: 0.5417\n",
      "Epoch 47/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1112 - accuracy: 0.5668 - val_loss: 1.1815 - val_accuracy: 0.5353\n",
      "Epoch 48/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1131 - accuracy: 0.5622 - val_loss: 1.1547 - val_accuracy: 0.5562\n",
      "Epoch 49/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1118 - accuracy: 0.5674 - val_loss: 1.1483 - val_accuracy: 0.5492\n",
      "Epoch 50/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1041 - accuracy: 0.5673 - val_loss: 1.1667 - val_accuracy: 0.5329\n",
      "Epoch 51/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.1004 - accuracy: 0.5702 - val_loss: 1.1720 - val_accuracy: 0.5390\n",
      "Epoch 52/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0965 - accuracy: 0.5724 - val_loss: 1.1444 - val_accuracy: 0.5540\n",
      "Epoch 53/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0866 - accuracy: 0.5759 - val_loss: 1.1359 - val_accuracy: 0.5597\n",
      "Epoch 54/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0831 - accuracy: 0.5776 - val_loss: 1.1257 - val_accuracy: 0.5647\n",
      "Epoch 55/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0839 - accuracy: 0.5769 - val_loss: 1.1383 - val_accuracy: 0.5535\n",
      "Epoch 56/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0777 - accuracy: 0.5832 - val_loss: 1.1386 - val_accuracy: 0.5571\n",
      "Epoch 57/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0740 - accuracy: 0.5834 - val_loss: 1.1142 - val_accuracy: 0.5654\n",
      "Epoch 58/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0696 - accuracy: 0.5837 - val_loss: 1.1545 - val_accuracy: 0.5536\n",
      "Epoch 59/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0701 - accuracy: 0.5854 - val_loss: 1.1394 - val_accuracy: 0.5590\n",
      "Epoch 60/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0693 - accuracy: 0.5844 - val_loss: 1.1221 - val_accuracy: 0.5642\n",
      "Epoch 61/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0581 - accuracy: 0.5893 - val_loss: 1.1285 - val_accuracy: 0.5593\n",
      "Epoch 62/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0565 - accuracy: 0.5899 - val_loss: 1.1250 - val_accuracy: 0.5589\n",
      "Epoch 63/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0530 - accuracy: 0.5910 - val_loss: 1.1201 - val_accuracy: 0.5614\n",
      "Epoch 64/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0537 - accuracy: 0.5914 - val_loss: 1.1575 - val_accuracy: 0.5532\n",
      "Epoch 65/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0526 - accuracy: 0.5942 - val_loss: 1.1137 - val_accuracy: 0.5657\n",
      "Epoch 66/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0481 - accuracy: 0.5951 - val_loss: 1.1036 - val_accuracy: 0.5760\n",
      "Epoch 67/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0416 - accuracy: 0.5975 - val_loss: 1.0899 - val_accuracy: 0.5814\n",
      "Epoch 68/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0354 - accuracy: 0.6020 - val_loss: 1.0976 - val_accuracy: 0.5790\n",
      "Epoch 69/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0375 - accuracy: 0.5982 - val_loss: 1.0959 - val_accuracy: 0.5757\n",
      "Epoch 70/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0319 - accuracy: 0.6020 - val_loss: 1.0966 - val_accuracy: 0.5783\n",
      "Epoch 71/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0294 - accuracy: 0.6010 - val_loss: 1.1021 - val_accuracy: 0.5782\n",
      "Epoch 72/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0276 - accuracy: 0.6043 - val_loss: 1.0868 - val_accuracy: 0.5849\n",
      "Epoch 73/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0251 - accuracy: 0.6046 - val_loss: 1.0902 - val_accuracy: 0.5842\n",
      "Epoch 74/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0212 - accuracy: 0.6058 - val_loss: 1.0874 - val_accuracy: 0.5825\n",
      "Epoch 75/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0202 - accuracy: 0.6075 - val_loss: 1.1129 - val_accuracy: 0.5788\n",
      "Epoch 76/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0166 - accuracy: 0.6062 - val_loss: 1.0822 - val_accuracy: 0.5844\n",
      "Epoch 77/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0174 - accuracy: 0.6109 - val_loss: 1.0857 - val_accuracy: 0.5849\n",
      "Epoch 78/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.6119 - val_loss: 1.0852 - val_accuracy: 0.5831\n",
      "Epoch 79/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0074 - accuracy: 0.6140 - val_loss: 1.0750 - val_accuracy: 0.5872\n",
      "Epoch 80/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0075 - accuracy: 0.6120 - val_loss: 1.1006 - val_accuracy: 0.5778\n",
      "Epoch 81/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0088 - accuracy: 0.6104 - val_loss: 1.0678 - val_accuracy: 0.5919\n",
      "Epoch 82/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 1.0025 - accuracy: 0.6128 - val_loss: 1.0890 - val_accuracy: 0.5876\n",
      "Epoch 83/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9967 - accuracy: 0.6189 - val_loss: 1.0762 - val_accuracy: 0.5928\n",
      "Epoch 84/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9961 - accuracy: 0.6188 - val_loss: 1.0857 - val_accuracy: 0.5840\n",
      "Epoch 85/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9935 - accuracy: 0.6158 - val_loss: 1.1010 - val_accuracy: 0.5744\n",
      "Epoch 86/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9972 - accuracy: 0.6168 - val_loss: 1.0989 - val_accuracy: 0.5789\n",
      "Epoch 87/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9910 - accuracy: 0.6201 - val_loss: 1.0765 - val_accuracy: 0.5872\n",
      "Epoch 88/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9906 - accuracy: 0.6202 - val_loss: 1.0925 - val_accuracy: 0.5878\n",
      "Epoch 89/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9877 - accuracy: 0.6205 - val_loss: 1.0936 - val_accuracy: 0.5903\n",
      "Epoch 90/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9834 - accuracy: 0.6239 - val_loss: 1.0691 - val_accuracy: 0.5929\n",
      "Epoch 91/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9802 - accuracy: 0.6254 - val_loss: 1.0669 - val_accuracy: 0.6011\n",
      "Epoch 92/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9795 - accuracy: 0.6247 - val_loss: 1.0567 - val_accuracy: 0.5967\n",
      "Epoch 93/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9788 - accuracy: 0.6248 - val_loss: 1.0602 - val_accuracy: 0.5987\n",
      "Epoch 94/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9765 - accuracy: 0.6247 - val_loss: 1.0741 - val_accuracy: 0.5918\n",
      "Epoch 95/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9709 - accuracy: 0.6274 - val_loss: 1.0521 - val_accuracy: 0.6064\n",
      "Epoch 96/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9747 - accuracy: 0.6265 - val_loss: 1.0756 - val_accuracy: 0.5908\n",
      "Epoch 97/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9752 - accuracy: 0.6278 - val_loss: 1.0682 - val_accuracy: 0.5964\n",
      "Epoch 98/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9675 - accuracy: 0.6298 - val_loss: 1.0480 - val_accuracy: 0.6072\n",
      "Epoch 99/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9656 - accuracy: 0.6272 - val_loss: 1.0541 - val_accuracy: 0.5965\n",
      "Epoch 100/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9673 - accuracy: 0.6276 - val_loss: 1.0651 - val_accuracy: 0.5929\n",
      "Epoch 101/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9576 - accuracy: 0.6326 - val_loss: 1.0593 - val_accuracy: 0.5981\n",
      "Epoch 102/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9546 - accuracy: 0.6358 - val_loss: 1.0697 - val_accuracy: 0.5958\n",
      "Epoch 103/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9544 - accuracy: 0.6328 - val_loss: 1.0664 - val_accuracy: 0.5950\n",
      "Epoch 104/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9572 - accuracy: 0.6357 - val_loss: 1.0625 - val_accuracy: 0.5976\n",
      "Epoch 105/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9552 - accuracy: 0.6357 - val_loss: 1.0604 - val_accuracy: 0.6008\n",
      "Epoch 106/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9575 - accuracy: 0.6330 - val_loss: 1.0510 - val_accuracy: 0.5992\n",
      "Epoch 107/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9531 - accuracy: 0.6357 - val_loss: 1.0627 - val_accuracy: 0.5983\n",
      "Epoch 108/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9531 - accuracy: 0.6339 - val_loss: 1.0511 - val_accuracy: 0.5969\n",
      "Epoch 109/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9509 - accuracy: 0.6370 - val_loss: 1.0390 - val_accuracy: 0.6124\n",
      "Epoch 110/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9508 - accuracy: 0.6363 - val_loss: 1.0512 - val_accuracy: 0.6072\n",
      "Epoch 111/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9482 - accuracy: 0.6384 - val_loss: 1.0455 - val_accuracy: 0.6114\n",
      "Epoch 112/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9466 - accuracy: 0.6348 - val_loss: 1.0522 - val_accuracy: 0.6054\n",
      "Epoch 113/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9409 - accuracy: 0.6402 - val_loss: 1.0386 - val_accuracy: 0.6143\n",
      "Epoch 114/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9404 - accuracy: 0.6367 - val_loss: 1.0664 - val_accuracy: 0.5947\n",
      "Epoch 115/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9403 - accuracy: 0.6394 - val_loss: 1.0425 - val_accuracy: 0.6069\n",
      "Epoch 116/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9349 - accuracy: 0.6427 - val_loss: 1.0376 - val_accuracy: 0.6099\n",
      "Epoch 117/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9378 - accuracy: 0.6392 - val_loss: 1.0550 - val_accuracy: 0.5960\n",
      "Epoch 118/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9345 - accuracy: 0.6429 - val_loss: 1.0422 - val_accuracy: 0.6065\n",
      "Epoch 119/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9355 - accuracy: 0.6416 - val_loss: 1.0417 - val_accuracy: 0.6092\n",
      "Epoch 120/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9301 - accuracy: 0.6439 - val_loss: 1.0394 - val_accuracy: 0.6129\n",
      "Epoch 121/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9287 - accuracy: 0.6470 - val_loss: 1.0640 - val_accuracy: 0.6028\n",
      "Epoch 122/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9315 - accuracy: 0.6435 - val_loss: 1.0442 - val_accuracy: 0.6042\n",
      "Epoch 123/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9340 - accuracy: 0.6416 - val_loss: 1.0470 - val_accuracy: 0.6115\n",
      "Epoch 124/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9209 - accuracy: 0.6500 - val_loss: 1.0420 - val_accuracy: 0.6087\n",
      "Epoch 125/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9233 - accuracy: 0.6485 - val_loss: 1.0295 - val_accuracy: 0.6128\n",
      "Epoch 126/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9274 - accuracy: 0.6485 - val_loss: 1.0474 - val_accuracy: 0.6007\n",
      "Epoch 127/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9228 - accuracy: 0.6445 - val_loss: 1.0373 - val_accuracy: 0.6089\n",
      "Epoch 128/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9208 - accuracy: 0.6479 - val_loss: 1.0243 - val_accuracy: 0.6158\n",
      "Epoch 129/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9119 - accuracy: 0.6524 - val_loss: 1.0320 - val_accuracy: 0.6175\n",
      "Epoch 130/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9188 - accuracy: 0.6498 - val_loss: 1.0555 - val_accuracy: 0.6004\n",
      "Epoch 131/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9169 - accuracy: 0.6514 - val_loss: 1.0360 - val_accuracy: 0.6139\n",
      "Epoch 132/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9196 - accuracy: 0.6484 - val_loss: 1.0283 - val_accuracy: 0.6200\n",
      "Epoch 133/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9134 - accuracy: 0.6495 - val_loss: 1.0389 - val_accuracy: 0.6162\n",
      "Epoch 134/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9121 - accuracy: 0.6525 - val_loss: 1.0394 - val_accuracy: 0.6111\n",
      "Epoch 135/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9072 - accuracy: 0.6544 - val_loss: 1.0494 - val_accuracy: 0.6067\n",
      "Epoch 136/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9111 - accuracy: 0.6530 - val_loss: 1.0306 - val_accuracy: 0.6136\n",
      "Epoch 137/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9061 - accuracy: 0.6545 - val_loss: 1.0367 - val_accuracy: 0.6154\n",
      "Epoch 138/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9035 - accuracy: 0.6562 - val_loss: 1.0302 - val_accuracy: 0.6117\n",
      "Epoch 139/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9017 - accuracy: 0.6544 - val_loss: 1.0342 - val_accuracy: 0.6224\n",
      "Epoch 140/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9014 - accuracy: 0.6563 - val_loss: 1.0462 - val_accuracy: 0.6069\n",
      "Epoch 141/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8995 - accuracy: 0.6582 - val_loss: 1.0320 - val_accuracy: 0.6142\n",
      "Epoch 142/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9031 - accuracy: 0.6547 - val_loss: 1.0143 - val_accuracy: 0.6251\n",
      "Epoch 143/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.9013 - accuracy: 0.6570 - val_loss: 1.0345 - val_accuracy: 0.6193\n",
      "Epoch 144/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8986 - accuracy: 0.6575 - val_loss: 1.0231 - val_accuracy: 0.6240\n",
      "Epoch 145/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8977 - accuracy: 0.6600 - val_loss: 1.0294 - val_accuracy: 0.6174\n",
      "Epoch 146/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8896 - accuracy: 0.6601 - val_loss: 1.0356 - val_accuracy: 0.6192\n",
      "Epoch 147/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8917 - accuracy: 0.6606 - val_loss: 1.0197 - val_accuracy: 0.6249\n",
      "Epoch 148/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8953 - accuracy: 0.6570 - val_loss: 1.0292 - val_accuracy: 0.6204\n",
      "Epoch 149/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8963 - accuracy: 0.6579 - val_loss: 1.0205 - val_accuracy: 0.6221\n",
      "Epoch 150/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8903 - accuracy: 0.6573 - val_loss: 1.0338 - val_accuracy: 0.6218\n",
      "Epoch 151/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8910 - accuracy: 0.6606 - val_loss: 1.0261 - val_accuracy: 0.6211\n",
      "Epoch 152/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8892 - accuracy: 0.6599 - val_loss: 1.0213 - val_accuracy: 0.6282\n",
      "Epoch 153/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8951 - accuracy: 0.6571 - val_loss: 1.0382 - val_accuracy: 0.6221\n",
      "Epoch 154/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8918 - accuracy: 0.6600 - val_loss: 1.0152 - val_accuracy: 0.6224\n",
      "Epoch 155/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8879 - accuracy: 0.6602 - val_loss: 1.0092 - val_accuracy: 0.6250\n",
      "Epoch 156/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8814 - accuracy: 0.6656 - val_loss: 1.0306 - val_accuracy: 0.6185\n",
      "Epoch 157/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8849 - accuracy: 0.6628 - val_loss: 1.0159 - val_accuracy: 0.6243\n",
      "Epoch 158/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8831 - accuracy: 0.6653 - val_loss: 1.0401 - val_accuracy: 0.6097\n",
      "Epoch 159/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8762 - accuracy: 0.6656 - val_loss: 1.0068 - val_accuracy: 0.6244\n",
      "Epoch 160/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8736 - accuracy: 0.6638 - val_loss: 1.0159 - val_accuracy: 0.6219\n",
      "Epoch 161/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8756 - accuracy: 0.6656 - val_loss: 1.0116 - val_accuracy: 0.6257\n",
      "Epoch 162/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8773 - accuracy: 0.6673 - val_loss: 0.9941 - val_accuracy: 0.6311\n",
      "Epoch 163/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8768 - accuracy: 0.6664 - val_loss: 1.0054 - val_accuracy: 0.6353\n",
      "Epoch 164/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8746 - accuracy: 0.6664 - val_loss: 1.0079 - val_accuracy: 0.6246\n",
      "Epoch 165/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8747 - accuracy: 0.6658 - val_loss: 1.0101 - val_accuracy: 0.6233\n",
      "Epoch 166/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8703 - accuracy: 0.6669 - val_loss: 1.0219 - val_accuracy: 0.6239\n",
      "Epoch 167/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8738 - accuracy: 0.6670 - val_loss: 1.0132 - val_accuracy: 0.6250\n",
      "Epoch 168/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8684 - accuracy: 0.6684 - val_loss: 1.0109 - val_accuracy: 0.6267\n",
      "Epoch 169/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8736 - accuracy: 0.6661 - val_loss: 1.0274 - val_accuracy: 0.6208\n",
      "Epoch 170/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8719 - accuracy: 0.6668 - val_loss: 1.0035 - val_accuracy: 0.6311\n",
      "Epoch 171/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8680 - accuracy: 0.6685 - val_loss: 1.0031 - val_accuracy: 0.6314\n",
      "Epoch 172/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8684 - accuracy: 0.6680 - val_loss: 1.0082 - val_accuracy: 0.6281\n",
      "Epoch 173/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8638 - accuracy: 0.6691 - val_loss: 1.0236 - val_accuracy: 0.6282\n",
      "Epoch 174/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8672 - accuracy: 0.6700 - val_loss: 1.0069 - val_accuracy: 0.6276\n",
      "Epoch 175/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8631 - accuracy: 0.6717 - val_loss: 1.0112 - val_accuracy: 0.6278\n",
      "Epoch 176/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8644 - accuracy: 0.6674 - val_loss: 1.0069 - val_accuracy: 0.6356\n",
      "Epoch 177/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8634 - accuracy: 0.6731 - val_loss: 0.9981 - val_accuracy: 0.6289\n",
      "Epoch 178/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8604 - accuracy: 0.6722 - val_loss: 0.9965 - val_accuracy: 0.6318\n",
      "Epoch 179/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8659 - accuracy: 0.6700 - val_loss: 0.9877 - val_accuracy: 0.6357\n",
      "Epoch 180/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8605 - accuracy: 0.6710 - val_loss: 1.0025 - val_accuracy: 0.6283\n",
      "Epoch 181/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8668 - accuracy: 0.6702 - val_loss: 0.9871 - val_accuracy: 0.6382\n",
      "Epoch 182/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8551 - accuracy: 0.6752 - val_loss: 0.9969 - val_accuracy: 0.6347\n",
      "Epoch 183/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8585 - accuracy: 0.6713 - val_loss: 0.9999 - val_accuracy: 0.6318\n",
      "Epoch 184/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8560 - accuracy: 0.6751 - val_loss: 1.0225 - val_accuracy: 0.6233\n",
      "Epoch 185/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8536 - accuracy: 0.6742 - val_loss: 0.9925 - val_accuracy: 0.6335\n",
      "Epoch 186/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8534 - accuracy: 0.6715 - val_loss: 1.0152 - val_accuracy: 0.6246\n",
      "Epoch 187/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8505 - accuracy: 0.6774 - val_loss: 0.9998 - val_accuracy: 0.6349\n",
      "Epoch 188/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8513 - accuracy: 0.6750 - val_loss: 1.0078 - val_accuracy: 0.6282\n",
      "Epoch 189/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8508 - accuracy: 0.6737 - val_loss: 0.9934 - val_accuracy: 0.6378\n",
      "Epoch 190/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8563 - accuracy: 0.6752 - val_loss: 0.9881 - val_accuracy: 0.6397\n",
      "Epoch 191/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8521 - accuracy: 0.6770 - val_loss: 0.9923 - val_accuracy: 0.6349\n",
      "Epoch 192/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8483 - accuracy: 0.6767 - val_loss: 0.9959 - val_accuracy: 0.6358\n",
      "Epoch 193/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8459 - accuracy: 0.6770 - val_loss: 0.9903 - val_accuracy: 0.6374\n",
      "Epoch 194/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8454 - accuracy: 0.6778 - val_loss: 0.9797 - val_accuracy: 0.6400\n",
      "Epoch 195/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8502 - accuracy: 0.6774 - val_loss: 0.9923 - val_accuracy: 0.6351\n",
      "Epoch 196/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8495 - accuracy: 0.6745 - val_loss: 0.9888 - val_accuracy: 0.6411\n",
      "Epoch 197/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8409 - accuracy: 0.6786 - val_loss: 0.9936 - val_accuracy: 0.6394\n",
      "Epoch 198/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8447 - accuracy: 0.6794 - val_loss: 0.9917 - val_accuracy: 0.6372\n",
      "Epoch 199/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8404 - accuracy: 0.6796 - val_loss: 1.0061 - val_accuracy: 0.6356\n",
      "Epoch 200/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8426 - accuracy: 0.6768 - val_loss: 0.9895 - val_accuracy: 0.6378\n",
      "Epoch 201/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8442 - accuracy: 0.6780 - val_loss: 0.9817 - val_accuracy: 0.6456\n",
      "Epoch 202/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8430 - accuracy: 0.6803 - val_loss: 1.0252 - val_accuracy: 0.6285\n",
      "Epoch 203/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8371 - accuracy: 0.6785 - val_loss: 1.0037 - val_accuracy: 0.6350\n",
      "Epoch 204/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8385 - accuracy: 0.6841 - val_loss: 0.9861 - val_accuracy: 0.6375\n",
      "Epoch 205/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8405 - accuracy: 0.6803 - val_loss: 0.9955 - val_accuracy: 0.6343\n",
      "Epoch 206/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8403 - accuracy: 0.6791 - val_loss: 0.9826 - val_accuracy: 0.6444\n",
      "Epoch 207/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8381 - accuracy: 0.6804 - val_loss: 0.9969 - val_accuracy: 0.6361\n",
      "Epoch 208/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8387 - accuracy: 0.6803 - val_loss: 0.9943 - val_accuracy: 0.6428\n",
      "Epoch 209/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8362 - accuracy: 0.6823 - val_loss: 0.9951 - val_accuracy: 0.6344\n",
      "Epoch 210/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8359 - accuracy: 0.6826 - val_loss: 0.9758 - val_accuracy: 0.6465\n",
      "Epoch 211/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8346 - accuracy: 0.6817 - val_loss: 1.0082 - val_accuracy: 0.6275\n",
      "Epoch 212/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8369 - accuracy: 0.6809 - val_loss: 0.9959 - val_accuracy: 0.6431\n",
      "Epoch 213/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8320 - accuracy: 0.6835 - val_loss: 0.9838 - val_accuracy: 0.6451\n",
      "Epoch 214/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8328 - accuracy: 0.6833 - val_loss: 1.0030 - val_accuracy: 0.6390\n",
      "Epoch 215/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8339 - accuracy: 0.6849 - val_loss: 0.9928 - val_accuracy: 0.6393\n",
      "Epoch 216/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8327 - accuracy: 0.6840 - val_loss: 0.9909 - val_accuracy: 0.6399\n",
      "Epoch 217/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8284 - accuracy: 0.6857 - val_loss: 0.9841 - val_accuracy: 0.6447\n",
      "Epoch 218/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8332 - accuracy: 0.6837 - val_loss: 1.0209 - val_accuracy: 0.6303\n",
      "Epoch 219/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8290 - accuracy: 0.6848 - val_loss: 0.9930 - val_accuracy: 0.6410\n",
      "Epoch 220/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8289 - accuracy: 0.6871 - val_loss: 1.0005 - val_accuracy: 0.6349\n",
      "Epoch 221/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8255 - accuracy: 0.6877 - val_loss: 0.9832 - val_accuracy: 0.6418\n",
      "Epoch 222/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8305 - accuracy: 0.6846 - val_loss: 0.9818 - val_accuracy: 0.6461\n",
      "Epoch 223/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8258 - accuracy: 0.6868 - val_loss: 1.0104 - val_accuracy: 0.6344\n",
      "Epoch 224/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8232 - accuracy: 0.6834 - val_loss: 0.9936 - val_accuracy: 0.6424\n",
      "Epoch 225/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8256 - accuracy: 0.6866 - val_loss: 0.9829 - val_accuracy: 0.6424\n",
      "Epoch 226/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8247 - accuracy: 0.6853 - val_loss: 0.9870 - val_accuracy: 0.6436\n",
      "Epoch 227/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8276 - accuracy: 0.6839 - val_loss: 0.9978 - val_accuracy: 0.6414\n",
      "Epoch 228/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8222 - accuracy: 0.6885 - val_loss: 1.0032 - val_accuracy: 0.6392\n",
      "Epoch 229/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8220 - accuracy: 0.6877 - val_loss: 1.0020 - val_accuracy: 0.6346\n",
      "Epoch 230/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8216 - accuracy: 0.6888 - val_loss: 0.9820 - val_accuracy: 0.6475\n",
      "Epoch 231/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8196 - accuracy: 0.6888 - val_loss: 0.9701 - val_accuracy: 0.6475\n",
      "Epoch 232/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8248 - accuracy: 0.6880 - val_loss: 0.9842 - val_accuracy: 0.6425\n",
      "Epoch 233/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8216 - accuracy: 0.6877 - val_loss: 0.9873 - val_accuracy: 0.6392\n",
      "Epoch 234/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8203 - accuracy: 0.6876 - val_loss: 0.9809 - val_accuracy: 0.6460\n",
      "Epoch 235/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8204 - accuracy: 0.6914 - val_loss: 1.0022 - val_accuracy: 0.6351\n",
      "Epoch 236/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8145 - accuracy: 0.6898 - val_loss: 0.9891 - val_accuracy: 0.6415\n",
      "Epoch 237/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8253 - accuracy: 0.6883 - val_loss: 0.9818 - val_accuracy: 0.6471\n",
      "Epoch 238/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8132 - accuracy: 0.6910 - val_loss: 0.9869 - val_accuracy: 0.6432\n",
      "Epoch 239/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8203 - accuracy: 0.6884 - val_loss: 0.9933 - val_accuracy: 0.6447\n",
      "Epoch 240/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8186 - accuracy: 0.6875 - val_loss: 0.9833 - val_accuracy: 0.6353\n",
      "Epoch 241/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8200 - accuracy: 0.6861 - val_loss: 0.9873 - val_accuracy: 0.6449\n",
      "Epoch 242/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8188 - accuracy: 0.6884 - val_loss: 0.9960 - val_accuracy: 0.6417\n",
      "Epoch 243/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8176 - accuracy: 0.6888 - val_loss: 0.9916 - val_accuracy: 0.6461\n",
      "Epoch 244/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8178 - accuracy: 0.6889 - val_loss: 0.9819 - val_accuracy: 0.6463\n",
      "Epoch 245/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8176 - accuracy: 0.6899 - val_loss: 1.0168 - val_accuracy: 0.6310\n",
      "Epoch 246/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8110 - accuracy: 0.6913 - val_loss: 0.9846 - val_accuracy: 0.6494\n",
      "Epoch 247/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8128 - accuracy: 0.6918 - val_loss: 0.9683 - val_accuracy: 0.6525\n",
      "Epoch 248/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8126 - accuracy: 0.6913 - val_loss: 0.9715 - val_accuracy: 0.6496\n",
      "Epoch 249/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8098 - accuracy: 0.6927 - val_loss: 0.9741 - val_accuracy: 0.6503\n",
      "Epoch 250/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8089 - accuracy: 0.6931 - val_loss: 0.9828 - val_accuracy: 0.6453\n",
      "Epoch 251/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8125 - accuracy: 0.6932 - val_loss: 0.9919 - val_accuracy: 0.6419\n",
      "Epoch 252/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8111 - accuracy: 0.6930 - val_loss: 0.9832 - val_accuracy: 0.6549\n",
      "Epoch 253/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8100 - accuracy: 0.6918 - val_loss: 0.9739 - val_accuracy: 0.6453\n",
      "Epoch 254/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8100 - accuracy: 0.6921 - val_loss: 0.9897 - val_accuracy: 0.6404\n",
      "Epoch 255/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8066 - accuracy: 0.6908 - val_loss: 0.9767 - val_accuracy: 0.6529\n",
      "Epoch 256/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8062 - accuracy: 0.6950 - val_loss: 0.9698 - val_accuracy: 0.6514\n",
      "Epoch 257/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8045 - accuracy: 0.6968 - val_loss: 0.9819 - val_accuracy: 0.6464\n",
      "Epoch 258/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8086 - accuracy: 0.6936 - val_loss: 1.0010 - val_accuracy: 0.6474\n",
      "Epoch 259/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8102 - accuracy: 0.6937 - val_loss: 0.9884 - val_accuracy: 0.6463\n",
      "Epoch 260/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8087 - accuracy: 0.6906 - val_loss: 0.9924 - val_accuracy: 0.6436\n",
      "Epoch 261/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8048 - accuracy: 0.6942 - val_loss: 0.9937 - val_accuracy: 0.6465\n",
      "Epoch 262/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8047 - accuracy: 0.6934 - val_loss: 0.9793 - val_accuracy: 0.6468\n",
      "Epoch 263/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8026 - accuracy: 0.6951 - val_loss: 0.9900 - val_accuracy: 0.6411\n",
      "Epoch 264/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8068 - accuracy: 0.6922 - val_loss: 0.9715 - val_accuracy: 0.6543\n",
      "Epoch 265/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8004 - accuracy: 0.6965 - val_loss: 0.9638 - val_accuracy: 0.6479\n",
      "Epoch 266/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8077 - accuracy: 0.6943 - val_loss: 0.9878 - val_accuracy: 0.6489\n",
      "Epoch 267/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7991 - accuracy: 0.6973 - val_loss: 0.9704 - val_accuracy: 0.6504\n",
      "Epoch 268/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8027 - accuracy: 0.6965 - val_loss: 0.9878 - val_accuracy: 0.6456\n",
      "Epoch 269/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8053 - accuracy: 0.6934 - val_loss: 0.9687 - val_accuracy: 0.6560\n",
      "Epoch 270/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7919 - accuracy: 0.6994 - val_loss: 0.9786 - val_accuracy: 0.6524\n",
      "Epoch 271/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8016 - accuracy: 0.6948 - val_loss: 0.9624 - val_accuracy: 0.6586\n",
      "Epoch 272/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8047 - accuracy: 0.6928 - val_loss: 0.9915 - val_accuracy: 0.6471\n",
      "Epoch 273/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8016 - accuracy: 0.6953 - val_loss: 0.9906 - val_accuracy: 0.6442\n",
      "Epoch 274/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7987 - accuracy: 0.6962 - val_loss: 0.9901 - val_accuracy: 0.6431\n",
      "Epoch 275/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7950 - accuracy: 0.7005 - val_loss: 0.9881 - val_accuracy: 0.6463\n",
      "Epoch 276/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8035 - accuracy: 0.6941 - val_loss: 0.9739 - val_accuracy: 0.6568\n",
      "Epoch 277/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7966 - accuracy: 0.6993 - val_loss: 0.9716 - val_accuracy: 0.6574\n",
      "Epoch 278/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7990 - accuracy: 0.6963 - val_loss: 0.9946 - val_accuracy: 0.6407\n",
      "Epoch 279/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8038 - accuracy: 0.6959 - val_loss: 0.9741 - val_accuracy: 0.6515\n",
      "Epoch 280/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7931 - accuracy: 0.6982 - val_loss: 0.9699 - val_accuracy: 0.6544\n",
      "Epoch 281/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7941 - accuracy: 0.6967 - val_loss: 0.9676 - val_accuracy: 0.6542\n",
      "Epoch 282/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7960 - accuracy: 0.7002 - val_loss: 0.9701 - val_accuracy: 0.6575\n",
      "Epoch 283/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7994 - accuracy: 0.6968 - val_loss: 0.9822 - val_accuracy: 0.6465\n",
      "Epoch 284/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7985 - accuracy: 0.6982 - val_loss: 0.9725 - val_accuracy: 0.6543\n",
      "Epoch 285/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7938 - accuracy: 0.6977 - val_loss: 0.9947 - val_accuracy: 0.6483\n",
      "Epoch 286/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7998 - accuracy: 0.6956 - val_loss: 0.9864 - val_accuracy: 0.6457\n",
      "Epoch 287/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7917 - accuracy: 0.6990 - val_loss: 0.9756 - val_accuracy: 0.6513\n",
      "Epoch 288/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.8005 - accuracy: 0.6945 - val_loss: 1.0014 - val_accuracy: 0.6425\n",
      "Epoch 289/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7969 - accuracy: 0.6995 - val_loss: 0.9677 - val_accuracy: 0.6529\n",
      "Epoch 290/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7975 - accuracy: 0.7003 - val_loss: 0.9824 - val_accuracy: 0.6517\n",
      "Epoch 291/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7997 - accuracy: 0.6984 - val_loss: 0.9755 - val_accuracy: 0.6526\n",
      "Epoch 292/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7908 - accuracy: 0.6984 - val_loss: 0.9848 - val_accuracy: 0.6526\n",
      "Epoch 293/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7871 - accuracy: 0.7002 - val_loss: 0.9845 - val_accuracy: 0.6468\n",
      "Epoch 294/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7898 - accuracy: 0.7000 - val_loss: 0.9624 - val_accuracy: 0.6549\n",
      "Epoch 295/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.7003 - val_loss: 0.9731 - val_accuracy: 0.6526\n",
      "Epoch 296/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7911 - accuracy: 0.6989 - val_loss: 0.9804 - val_accuracy: 0.6460\n",
      "Epoch 297/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7874 - accuracy: 0.7004 - val_loss: 0.9848 - val_accuracy: 0.6515\n",
      "Epoch 298/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7927 - accuracy: 0.6981 - val_loss: 0.9739 - val_accuracy: 0.6551\n",
      "Epoch 299/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7848 - accuracy: 0.7011 - val_loss: 0.9619 - val_accuracy: 0.6538\n",
      "Epoch 300/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7899 - accuracy: 0.6998 - val_loss: 0.9820 - val_accuracy: 0.6564\n",
      "Epoch 301/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7900 - accuracy: 0.6993 - val_loss: 0.9728 - val_accuracy: 0.6560\n",
      "Epoch 302/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7855 - accuracy: 0.7024 - val_loss: 1.0306 - val_accuracy: 0.6283\n",
      "Epoch 303/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7878 - accuracy: 0.7014 - val_loss: 0.9592 - val_accuracy: 0.6587\n",
      "Epoch 304/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7833 - accuracy: 0.7010 - val_loss: 0.9855 - val_accuracy: 0.6546\n",
      "Epoch 305/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7855 - accuracy: 0.7034 - val_loss: 0.9632 - val_accuracy: 0.6554\n",
      "Epoch 306/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7890 - accuracy: 0.7010 - val_loss: 0.9689 - val_accuracy: 0.6575\n",
      "Epoch 307/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7854 - accuracy: 0.7016 - val_loss: 0.9787 - val_accuracy: 0.6481\n",
      "Epoch 308/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7884 - accuracy: 0.7000 - val_loss: 0.9771 - val_accuracy: 0.6503\n",
      "Epoch 309/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7806 - accuracy: 0.7032 - val_loss: 0.9850 - val_accuracy: 0.6506\n",
      "Epoch 310/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7865 - accuracy: 0.7030 - val_loss: 0.9720 - val_accuracy: 0.6506\n",
      "Epoch 311/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7878 - accuracy: 0.7006 - val_loss: 0.9624 - val_accuracy: 0.6574\n",
      "Epoch 312/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7847 - accuracy: 0.7023 - val_loss: 0.9866 - val_accuracy: 0.6497\n",
      "Epoch 313/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7785 - accuracy: 0.7025 - val_loss: 0.9788 - val_accuracy: 0.6528\n",
      "Epoch 314/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7905 - accuracy: 0.7010 - val_loss: 0.9743 - val_accuracy: 0.6501\n",
      "Epoch 315/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7894 - accuracy: 0.7015 - val_loss: 0.9894 - val_accuracy: 0.6531\n",
      "Epoch 316/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7820 - accuracy: 0.7019 - val_loss: 0.9584 - val_accuracy: 0.6600\n",
      "Epoch 317/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7849 - accuracy: 0.7017 - val_loss: 0.9721 - val_accuracy: 0.6515\n",
      "Epoch 318/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7806 - accuracy: 0.7025 - val_loss: 0.9650 - val_accuracy: 0.6560\n",
      "Epoch 319/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7822 - accuracy: 0.7015 - val_loss: 0.9765 - val_accuracy: 0.6562\n",
      "Epoch 320/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7837 - accuracy: 0.7043 - val_loss: 0.9862 - val_accuracy: 0.6443\n",
      "Epoch 321/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7786 - accuracy: 0.7016 - val_loss: 0.9838 - val_accuracy: 0.6539\n",
      "Epoch 322/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7719 - accuracy: 0.7064 - val_loss: 0.9685 - val_accuracy: 0.6617\n",
      "Epoch 323/1000\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7832 - accuracy: 0.7016 - val_loss: 0.9854 - val_accuracy: 0.6463\n",
      "Epoch 324/1000\n",
      "450/450 [==============================] - 3s 6ms/step - loss: 0.7780 - accuracy: 0.7044 - val_loss: 0.9685 - val_accuracy: 0.6601\n",
      "Epoch 325/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7815 - accuracy: 0.7038 - val_loss: 0.9698 - val_accuracy: 0.6550\n",
      "Epoch 326/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7773 - accuracy: 0.7042 - val_loss: 0.9638 - val_accuracy: 0.6578\n",
      "Epoch 327/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7770 - accuracy: 0.7041 - val_loss: 0.9644 - val_accuracy: 0.6608\n",
      "Epoch 328/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7829 - accuracy: 0.7028 - val_loss: 0.9793 - val_accuracy: 0.6528\n",
      "Epoch 329/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7797 - accuracy: 0.7039 - val_loss: 0.9823 - val_accuracy: 0.6532\n",
      "Epoch 330/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7755 - accuracy: 0.7048 - val_loss: 0.9722 - val_accuracy: 0.6525\n",
      "Epoch 331/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7757 - accuracy: 0.7041 - val_loss: 0.9737 - val_accuracy: 0.6556\n",
      "Epoch 332/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7744 - accuracy: 0.7053 - val_loss: 0.9822 - val_accuracy: 0.6533\n",
      "Epoch 333/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7756 - accuracy: 0.7064 - val_loss: 1.0080 - val_accuracy: 0.6338\n",
      "Epoch 334/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7774 - accuracy: 0.7041 - val_loss: 0.9808 - val_accuracy: 0.6468\n",
      "Epoch 335/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7738 - accuracy: 0.7053 - val_loss: 0.9664 - val_accuracy: 0.6619\n",
      "Epoch 336/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7780 - accuracy: 0.7055 - val_loss: 0.9649 - val_accuracy: 0.6597\n",
      "Epoch 337/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7779 - accuracy: 0.7036 - val_loss: 0.9646 - val_accuracy: 0.6633\n",
      "Epoch 338/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7716 - accuracy: 0.7066 - val_loss: 0.9699 - val_accuracy: 0.6499\n",
      "Epoch 339/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7785 - accuracy: 0.7033 - val_loss: 0.9715 - val_accuracy: 0.6576\n",
      "Epoch 340/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.7036 - val_loss: 0.9736 - val_accuracy: 0.6568\n",
      "Epoch 341/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7755 - accuracy: 0.7067 - val_loss: 0.9600 - val_accuracy: 0.6599\n",
      "Epoch 342/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7685 - accuracy: 0.7084 - val_loss: 0.9629 - val_accuracy: 0.6637\n",
      "Epoch 343/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7785 - accuracy: 0.7022 - val_loss: 0.9762 - val_accuracy: 0.6629\n",
      "Epoch 344/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7778 - accuracy: 0.7044 - val_loss: 0.9631 - val_accuracy: 0.6610\n",
      "Epoch 345/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7641 - accuracy: 0.7108 - val_loss: 0.9869 - val_accuracy: 0.6501\n",
      "Epoch 346/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7779 - accuracy: 0.7064 - val_loss: 0.9865 - val_accuracy: 0.6567\n",
      "Epoch 347/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7675 - accuracy: 0.7078 - val_loss: 0.9766 - val_accuracy: 0.6581\n",
      "Epoch 348/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7677 - accuracy: 0.7105 - val_loss: 0.9553 - val_accuracy: 0.6703\n",
      "Epoch 349/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7748 - accuracy: 0.7076 - val_loss: 0.9590 - val_accuracy: 0.6606\n",
      "Epoch 350/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7720 - accuracy: 0.7064 - val_loss: 0.9697 - val_accuracy: 0.6599\n",
      "Epoch 351/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7665 - accuracy: 0.7080 - val_loss: 0.9605 - val_accuracy: 0.6569\n",
      "Epoch 352/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7716 - accuracy: 0.7084 - val_loss: 0.9916 - val_accuracy: 0.6544\n",
      "Epoch 353/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7703 - accuracy: 0.7060 - val_loss: 0.9689 - val_accuracy: 0.6671\n",
      "Epoch 354/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7705 - accuracy: 0.7086 - val_loss: 0.9632 - val_accuracy: 0.6599\n",
      "Epoch 355/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7680 - accuracy: 0.7083 - val_loss: 0.9833 - val_accuracy: 0.6581\n",
      "Epoch 356/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7587 - accuracy: 0.7122 - val_loss: 0.9838 - val_accuracy: 0.6615\n",
      "Epoch 357/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7721 - accuracy: 0.7080 - val_loss: 0.9662 - val_accuracy: 0.6633\n",
      "Epoch 358/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7708 - accuracy: 0.7059 - val_loss: 0.9703 - val_accuracy: 0.6528\n",
      "Epoch 359/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7713 - accuracy: 0.7103 - val_loss: 0.9706 - val_accuracy: 0.6558\n",
      "Epoch 360/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7708 - accuracy: 0.7043 - val_loss: 0.9635 - val_accuracy: 0.6600\n",
      "Epoch 361/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7646 - accuracy: 0.7113 - val_loss: 0.9645 - val_accuracy: 0.6618\n",
      "Epoch 362/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7704 - accuracy: 0.7112 - val_loss: 0.9657 - val_accuracy: 0.6583\n",
      "Epoch 363/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7678 - accuracy: 0.7079 - val_loss: 0.9781 - val_accuracy: 0.6558\n",
      "Epoch 364/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7595 - accuracy: 0.7108 - val_loss: 0.9653 - val_accuracy: 0.6697\n",
      "Epoch 365/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7639 - accuracy: 0.7120 - val_loss: 0.9782 - val_accuracy: 0.6551\n",
      "Epoch 366/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7649 - accuracy: 0.7083 - val_loss: 0.9653 - val_accuracy: 0.6665\n",
      "Epoch 367/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7629 - accuracy: 0.7108 - val_loss: 0.9795 - val_accuracy: 0.6576\n",
      "Epoch 368/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7649 - accuracy: 0.7089 - val_loss: 0.9785 - val_accuracy: 0.6517\n",
      "Epoch 369/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7703 - accuracy: 0.7084 - val_loss: 0.9794 - val_accuracy: 0.6593\n",
      "Epoch 370/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7699 - accuracy: 0.7109 - val_loss: 0.9796 - val_accuracy: 0.6492\n",
      "Epoch 371/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7655 - accuracy: 0.7074 - val_loss: 0.9693 - val_accuracy: 0.6628\n",
      "Epoch 372/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7641 - accuracy: 0.7092 - val_loss: 0.9553 - val_accuracy: 0.6643\n",
      "Epoch 373/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7619 - accuracy: 0.7094 - val_loss: 0.9915 - val_accuracy: 0.6562\n",
      "Epoch 374/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7656 - accuracy: 0.7108 - val_loss: 0.9589 - val_accuracy: 0.6626\n",
      "Epoch 375/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7731 - accuracy: 0.7063 - val_loss: 0.9791 - val_accuracy: 0.6543\n",
      "Epoch 376/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7655 - accuracy: 0.7088 - val_loss: 0.9636 - val_accuracy: 0.6633\n",
      "Epoch 377/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7553 - accuracy: 0.7126 - val_loss: 0.9589 - val_accuracy: 0.6647\n",
      "Epoch 378/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7595 - accuracy: 0.7130 - val_loss: 0.9702 - val_accuracy: 0.6597\n",
      "Epoch 379/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7621 - accuracy: 0.7128 - val_loss: 0.9839 - val_accuracy: 0.6568\n",
      "Epoch 380/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7593 - accuracy: 0.7133 - val_loss: 0.9574 - val_accuracy: 0.6644\n",
      "Epoch 381/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7648 - accuracy: 0.7078 - val_loss: 0.9862 - val_accuracy: 0.6476\n",
      "Epoch 382/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7624 - accuracy: 0.7125 - val_loss: 0.9623 - val_accuracy: 0.6628\n",
      "Epoch 383/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7577 - accuracy: 0.7126 - val_loss: 0.9572 - val_accuracy: 0.6629\n",
      "Epoch 384/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7622 - accuracy: 0.7102 - val_loss: 0.9866 - val_accuracy: 0.6511\n",
      "Epoch 385/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7606 - accuracy: 0.7127 - val_loss: 0.9830 - val_accuracy: 0.6567\n",
      "Epoch 386/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7587 - accuracy: 0.7135 - val_loss: 0.9926 - val_accuracy: 0.6604\n",
      "Epoch 387/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7642 - accuracy: 0.7097 - val_loss: 0.9767 - val_accuracy: 0.6549\n",
      "Epoch 388/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7555 - accuracy: 0.7133 - val_loss: 0.9604 - val_accuracy: 0.6676\n",
      "Epoch 389/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7533 - accuracy: 0.7137 - val_loss: 0.9427 - val_accuracy: 0.6731\n",
      "Epoch 390/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7599 - accuracy: 0.7114 - val_loss: 0.9614 - val_accuracy: 0.6594\n",
      "Epoch 391/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7628 - accuracy: 0.7111 - val_loss: 0.9607 - val_accuracy: 0.6662\n",
      "Epoch 392/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7593 - accuracy: 0.7126 - val_loss: 0.9594 - val_accuracy: 0.6628\n",
      "Epoch 393/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7529 - accuracy: 0.7158 - val_loss: 0.9636 - val_accuracy: 0.6672\n",
      "Epoch 394/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7557 - accuracy: 0.7131 - val_loss: 0.9592 - val_accuracy: 0.6637\n",
      "Epoch 395/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7601 - accuracy: 0.7122 - val_loss: 0.9590 - val_accuracy: 0.6664\n",
      "Epoch 396/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7585 - accuracy: 0.7126 - val_loss: 0.9622 - val_accuracy: 0.6622\n",
      "Epoch 397/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7632 - accuracy: 0.7072 - val_loss: 0.9680 - val_accuracy: 0.6643\n",
      "Epoch 398/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7594 - accuracy: 0.7111 - val_loss: 0.9851 - val_accuracy: 0.6532\n",
      "Epoch 399/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7563 - accuracy: 0.7107 - val_loss: 0.9665 - val_accuracy: 0.6669\n",
      "Epoch 400/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7523 - accuracy: 0.7150 - val_loss: 0.9684 - val_accuracy: 0.6597\n",
      "Epoch 401/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7565 - accuracy: 0.7114 - val_loss: 0.9617 - val_accuracy: 0.6631\n",
      "Epoch 402/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7507 - accuracy: 0.7150 - val_loss: 0.9755 - val_accuracy: 0.6635\n",
      "Epoch 403/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7511 - accuracy: 0.7140 - val_loss: 0.9722 - val_accuracy: 0.6636\n",
      "Epoch 404/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7566 - accuracy: 0.7134 - val_loss: 0.9678 - val_accuracy: 0.6607\n",
      "Epoch 405/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7589 - accuracy: 0.7115 - val_loss: 0.9582 - val_accuracy: 0.6678\n",
      "Epoch 406/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7567 - accuracy: 0.7139 - val_loss: 0.9694 - val_accuracy: 0.6600\n",
      "Epoch 407/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7513 - accuracy: 0.7155 - val_loss: 0.9842 - val_accuracy: 0.6619\n",
      "Epoch 408/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7484 - accuracy: 0.7161 - val_loss: 0.9965 - val_accuracy: 0.6536\n",
      "Epoch 409/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7551 - accuracy: 0.7135 - val_loss: 0.9635 - val_accuracy: 0.6675\n",
      "Epoch 410/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7541 - accuracy: 0.7137 - val_loss: 0.9649 - val_accuracy: 0.6625\n",
      "Epoch 411/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7569 - accuracy: 0.7120 - val_loss: 0.9636 - val_accuracy: 0.6676\n",
      "Epoch 412/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7506 - accuracy: 0.7138 - val_loss: 0.9697 - val_accuracy: 0.6599\n",
      "Epoch 413/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7495 - accuracy: 0.7149 - val_loss: 0.9602 - val_accuracy: 0.6649\n",
      "Epoch 414/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7604 - accuracy: 0.7115 - val_loss: 0.9663 - val_accuracy: 0.6657\n",
      "Epoch 415/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7559 - accuracy: 0.7135 - val_loss: 0.9530 - val_accuracy: 0.6686\n",
      "Epoch 416/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7481 - accuracy: 0.7161 - val_loss: 0.9561 - val_accuracy: 0.6644\n",
      "Epoch 417/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7567 - accuracy: 0.7131 - val_loss: 0.9699 - val_accuracy: 0.6662\n",
      "Epoch 418/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7575 - accuracy: 0.7130 - val_loss: 0.9582 - val_accuracy: 0.6708\n",
      "Epoch 419/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7475 - accuracy: 0.7153 - val_loss: 0.9811 - val_accuracy: 0.6586\n",
      "Epoch 420/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7556 - accuracy: 0.7113 - val_loss: 0.9704 - val_accuracy: 0.6625\n",
      "Epoch 421/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7532 - accuracy: 0.7167 - val_loss: 0.9683 - val_accuracy: 0.6676\n",
      "Epoch 422/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7543 - accuracy: 0.7169 - val_loss: 0.9615 - val_accuracy: 0.6667\n",
      "Epoch 423/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7479 - accuracy: 0.7178 - val_loss: 0.9765 - val_accuracy: 0.6599\n",
      "Epoch 424/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7514 - accuracy: 0.7164 - val_loss: 0.9682 - val_accuracy: 0.6658\n",
      "Epoch 425/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7518 - accuracy: 0.7150 - val_loss: 0.9864 - val_accuracy: 0.6611\n",
      "Epoch 426/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7490 - accuracy: 0.7138 - val_loss: 0.9850 - val_accuracy: 0.6587\n",
      "Epoch 427/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7500 - accuracy: 0.7175 - val_loss: 0.9648 - val_accuracy: 0.6651\n",
      "Epoch 428/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7440 - accuracy: 0.7184 - val_loss: 0.9682 - val_accuracy: 0.6612\n",
      "Epoch 429/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7432 - accuracy: 0.7172 - val_loss: 0.9664 - val_accuracy: 0.6654\n",
      "Epoch 430/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7513 - accuracy: 0.7151 - val_loss: 0.9705 - val_accuracy: 0.6636\n",
      "Epoch 431/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7466 - accuracy: 0.7195 - val_loss: 0.9602 - val_accuracy: 0.6722\n",
      "Epoch 432/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7457 - accuracy: 0.7182 - val_loss: 0.9667 - val_accuracy: 0.6671\n",
      "Epoch 433/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7531 - accuracy: 0.7134 - val_loss: 0.9717 - val_accuracy: 0.6671\n",
      "Epoch 434/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7391 - accuracy: 0.7192 - val_loss: 0.9724 - val_accuracy: 0.6603\n",
      "Epoch 435/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7420 - accuracy: 0.7166 - val_loss: 0.9887 - val_accuracy: 0.6578\n",
      "Epoch 436/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7563 - accuracy: 0.7126 - val_loss: 0.9761 - val_accuracy: 0.6624\n",
      "Epoch 437/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7521 - accuracy: 0.7139 - val_loss: 0.9894 - val_accuracy: 0.6513\n",
      "Epoch 438/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7401 - accuracy: 0.7185 - val_loss: 0.9461 - val_accuracy: 0.6744\n",
      "Epoch 439/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7446 - accuracy: 0.7183 - val_loss: 0.9960 - val_accuracy: 0.6611\n",
      "Epoch 440/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7381 - accuracy: 0.7184 - val_loss: 0.9665 - val_accuracy: 0.6667\n",
      "Epoch 441/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7437 - accuracy: 0.7159 - val_loss: 0.9714 - val_accuracy: 0.6721\n",
      "Epoch 442/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7424 - accuracy: 0.7181 - val_loss: 0.9641 - val_accuracy: 0.6682\n",
      "Epoch 443/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7511 - accuracy: 0.7148 - val_loss: 0.9635 - val_accuracy: 0.6687\n",
      "Epoch 444/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7477 - accuracy: 0.7157 - val_loss: 0.9896 - val_accuracy: 0.6635\n",
      "Epoch 445/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.7135 - val_loss: 0.9622 - val_accuracy: 0.6697\n",
      "Epoch 446/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7505 - accuracy: 0.7165 - val_loss: 0.9993 - val_accuracy: 0.6575\n",
      "Epoch 447/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7439 - accuracy: 0.7175 - val_loss: 0.9564 - val_accuracy: 0.6721\n",
      "Epoch 448/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7478 - accuracy: 0.7137 - val_loss: 0.9811 - val_accuracy: 0.6561\n",
      "Epoch 449/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7394 - accuracy: 0.7188 - val_loss: 0.9624 - val_accuracy: 0.6737\n",
      "Epoch 450/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7466 - accuracy: 0.7184 - val_loss: 0.9605 - val_accuracy: 0.6701\n",
      "Epoch 451/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7427 - accuracy: 0.7188 - val_loss: 0.9801 - val_accuracy: 0.6646\n",
      "Epoch 452/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7422 - accuracy: 0.7193 - val_loss: 0.9567 - val_accuracy: 0.6707\n",
      "Epoch 453/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7381 - accuracy: 0.7222 - val_loss: 0.9574 - val_accuracy: 0.6696\n",
      "Epoch 454/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7413 - accuracy: 0.7190 - val_loss: 0.9741 - val_accuracy: 0.6676\n",
      "Epoch 455/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7403 - accuracy: 0.7174 - val_loss: 0.9516 - val_accuracy: 0.6683\n",
      "Epoch 456/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7388 - accuracy: 0.7208 - val_loss: 0.9581 - val_accuracy: 0.6671\n",
      "Epoch 457/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.7152 - val_loss: 0.9761 - val_accuracy: 0.6667\n",
      "Epoch 458/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7407 - accuracy: 0.7161 - val_loss: 0.9642 - val_accuracy: 0.6729\n",
      "Epoch 459/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7443 - accuracy: 0.7180 - val_loss: 0.9615 - val_accuracy: 0.6672\n",
      "Epoch 460/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7397 - accuracy: 0.7202 - val_loss: 0.9696 - val_accuracy: 0.6681\n",
      "Epoch 461/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7400 - accuracy: 0.7193 - val_loss: 0.9798 - val_accuracy: 0.6600\n",
      "Epoch 462/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7435 - accuracy: 0.7184 - val_loss: 0.9608 - val_accuracy: 0.6719\n",
      "Epoch 463/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7378 - accuracy: 0.7197 - val_loss: 0.9582 - val_accuracy: 0.6733\n",
      "Epoch 464/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7443 - accuracy: 0.7204 - val_loss: 0.9701 - val_accuracy: 0.6662\n",
      "Epoch 465/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.7173 - val_loss: 0.9766 - val_accuracy: 0.6657\n",
      "Epoch 466/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7346 - accuracy: 0.7235 - val_loss: 0.9677 - val_accuracy: 0.6724\n",
      "Epoch 467/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7454 - accuracy: 0.7183 - val_loss: 0.9892 - val_accuracy: 0.6575\n",
      "Epoch 468/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7411 - accuracy: 0.7209 - val_loss: 0.9547 - val_accuracy: 0.6704\n",
      "Epoch 469/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7367 - accuracy: 0.7210 - val_loss: 0.9646 - val_accuracy: 0.6686\n",
      "Epoch 470/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7340 - accuracy: 0.7218 - val_loss: 0.9483 - val_accuracy: 0.6704\n",
      "Epoch 471/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7404 - accuracy: 0.7196 - val_loss: 0.9693 - val_accuracy: 0.6697\n",
      "Epoch 472/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7349 - accuracy: 0.7212 - val_loss: 0.9771 - val_accuracy: 0.6637\n",
      "Epoch 473/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7438 - accuracy: 0.7162 - val_loss: 0.9681 - val_accuracy: 0.6661\n",
      "Epoch 474/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7332 - accuracy: 0.7207 - val_loss: 0.9715 - val_accuracy: 0.6693\n",
      "Epoch 475/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7395 - accuracy: 0.7196 - val_loss: 0.9485 - val_accuracy: 0.6747\n",
      "Epoch 476/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7316 - accuracy: 0.7228 - val_loss: 0.9995 - val_accuracy: 0.6581\n",
      "Epoch 477/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7409 - accuracy: 0.7235 - val_loss: 0.9549 - val_accuracy: 0.6733\n",
      "Epoch 478/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7350 - accuracy: 0.7222 - val_loss: 0.9605 - val_accuracy: 0.6683\n",
      "Epoch 479/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7428 - accuracy: 0.7173 - val_loss: 0.9704 - val_accuracy: 0.6686\n",
      "Epoch 480/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7302 - accuracy: 0.7231 - val_loss: 0.9732 - val_accuracy: 0.6696\n",
      "Epoch 481/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7341 - accuracy: 0.7232 - val_loss: 0.9482 - val_accuracy: 0.6708\n",
      "Epoch 482/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7356 - accuracy: 0.7229 - val_loss: 0.9533 - val_accuracy: 0.6743\n",
      "Epoch 483/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7350 - accuracy: 0.7227 - val_loss: 0.9678 - val_accuracy: 0.6712\n",
      "Epoch 484/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7309 - accuracy: 0.7239 - val_loss: 0.9686 - val_accuracy: 0.6703\n",
      "Epoch 485/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7385 - accuracy: 0.7208 - val_loss: 0.9783 - val_accuracy: 0.6714\n",
      "Epoch 486/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7352 - accuracy: 0.7201 - val_loss: 0.9726 - val_accuracy: 0.6626\n",
      "Epoch 487/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7405 - accuracy: 0.7198 - val_loss: 0.9688 - val_accuracy: 0.6637\n",
      "Epoch 488/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7351 - accuracy: 0.7219 - val_loss: 0.9549 - val_accuracy: 0.6725\n",
      "Epoch 489/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7379 - accuracy: 0.7219 - val_loss: 0.9442 - val_accuracy: 0.6693\n",
      "Epoch 490/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7401 - accuracy: 0.7192 - val_loss: 0.9596 - val_accuracy: 0.6675\n",
      "Epoch 491/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7337 - accuracy: 0.7219 - val_loss: 0.9502 - val_accuracy: 0.6714\n",
      "Epoch 492/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7436 - accuracy: 0.7184 - val_loss: 0.9644 - val_accuracy: 0.6703\n",
      "Epoch 493/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7402 - accuracy: 0.7177 - val_loss: 0.9603 - val_accuracy: 0.6699\n",
      "Epoch 494/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7311 - accuracy: 0.7234 - val_loss: 0.9555 - val_accuracy: 0.6757\n",
      "Epoch 495/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.7224 - val_loss: 0.9579 - val_accuracy: 0.6675\n",
      "Epoch 496/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7353 - accuracy: 0.7223 - val_loss: 0.9712 - val_accuracy: 0.6712\n",
      "Epoch 497/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7312 - accuracy: 0.7225 - val_loss: 0.9647 - val_accuracy: 0.6756\n",
      "Epoch 498/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7319 - accuracy: 0.7231 - val_loss: 0.9645 - val_accuracy: 0.6724\n",
      "Epoch 499/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.7237 - val_loss: 0.9589 - val_accuracy: 0.6726\n",
      "Epoch 500/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7348 - accuracy: 0.7228 - val_loss: 0.9686 - val_accuracy: 0.6692\n",
      "Epoch 501/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7359 - accuracy: 0.7223 - val_loss: 0.9676 - val_accuracy: 0.6683\n",
      "Epoch 502/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7292 - accuracy: 0.7251 - val_loss: 0.9592 - val_accuracy: 0.6754\n",
      "Epoch 503/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7306 - accuracy: 0.7217 - val_loss: 0.9756 - val_accuracy: 0.6737\n",
      "Epoch 504/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7320 - accuracy: 0.7223 - val_loss: 0.9600 - val_accuracy: 0.6740\n",
      "Epoch 505/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7258 - accuracy: 0.7243 - val_loss: 0.9688 - val_accuracy: 0.6678\n",
      "Epoch 506/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7272 - accuracy: 0.7266 - val_loss: 0.9745 - val_accuracy: 0.6681\n",
      "Epoch 507/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7352 - accuracy: 0.7215 - val_loss: 0.9728 - val_accuracy: 0.6681\n",
      "Epoch 508/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7397 - accuracy: 0.7190 - val_loss: 0.9597 - val_accuracy: 0.6721\n",
      "Epoch 509/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7243 - accuracy: 0.7249 - val_loss: 0.9745 - val_accuracy: 0.6658\n",
      "Epoch 510/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7356 - accuracy: 0.7217 - val_loss: 0.9764 - val_accuracy: 0.6704\n",
      "Epoch 511/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7310 - accuracy: 0.7237 - val_loss: 0.9725 - val_accuracy: 0.6728\n",
      "Epoch 512/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7317 - accuracy: 0.7210 - val_loss: 0.9686 - val_accuracy: 0.6699\n",
      "Epoch 513/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7232 - accuracy: 0.7254 - val_loss: 0.9753 - val_accuracy: 0.6672\n",
      "Epoch 514/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7310 - accuracy: 0.7217 - val_loss: 0.9728 - val_accuracy: 0.6644\n",
      "Epoch 515/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7291 - accuracy: 0.7235 - val_loss: 0.9548 - val_accuracy: 0.6765\n",
      "Epoch 516/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7297 - accuracy: 0.7230 - val_loss: 0.9666 - val_accuracy: 0.6725\n",
      "Epoch 517/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7302 - accuracy: 0.7242 - val_loss: 0.9830 - val_accuracy: 0.6597\n",
      "Epoch 518/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7306 - accuracy: 0.7231 - val_loss: 0.9892 - val_accuracy: 0.6622\n",
      "Epoch 519/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7262 - accuracy: 0.7251 - val_loss: 0.9706 - val_accuracy: 0.6683\n",
      "Epoch 520/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7303 - accuracy: 0.7233 - val_loss: 0.9715 - val_accuracy: 0.6690\n",
      "Epoch 521/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7291 - accuracy: 0.7268 - val_loss: 0.9508 - val_accuracy: 0.6721\n",
      "Epoch 522/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7254 - accuracy: 0.7232 - val_loss: 0.9709 - val_accuracy: 0.6693\n",
      "Epoch 523/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7363 - accuracy: 0.7194 - val_loss: 0.9775 - val_accuracy: 0.6707\n",
      "Epoch 524/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7252 - val_loss: 0.9669 - val_accuracy: 0.6754\n",
      "Epoch 525/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7356 - accuracy: 0.7195 - val_loss: 0.9872 - val_accuracy: 0.6650\n",
      "Epoch 526/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7320 - accuracy: 0.7237 - val_loss: 0.9700 - val_accuracy: 0.6736\n",
      "Epoch 527/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7275 - accuracy: 0.7240 - val_loss: 0.9759 - val_accuracy: 0.6669\n",
      "Epoch 528/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7258 - accuracy: 0.7258 - val_loss: 0.9546 - val_accuracy: 0.6789\n",
      "Epoch 529/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7367 - accuracy: 0.7200 - val_loss: 0.9597 - val_accuracy: 0.6729\n",
      "Epoch 530/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7240 - accuracy: 0.7263 - val_loss: 0.9829 - val_accuracy: 0.6658\n",
      "Epoch 531/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7222 - accuracy: 0.7260 - val_loss: 0.9479 - val_accuracy: 0.6740\n",
      "Epoch 532/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7354 - accuracy: 0.7220 - val_loss: 0.9523 - val_accuracy: 0.6729\n",
      "Epoch 533/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7193 - accuracy: 0.7276 - val_loss: 0.9701 - val_accuracy: 0.6683\n",
      "Epoch 534/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7237 - accuracy: 0.7260 - val_loss: 0.9736 - val_accuracy: 0.6718\n",
      "Epoch 535/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7268 - accuracy: 0.7276 - val_loss: 0.9707 - val_accuracy: 0.6665\n",
      "Epoch 536/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7202 - accuracy: 0.7292 - val_loss: 0.9739 - val_accuracy: 0.6737\n",
      "Epoch 537/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7339 - accuracy: 0.7229 - val_loss: 0.9619 - val_accuracy: 0.6739\n",
      "Epoch 538/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7308 - accuracy: 0.7209 - val_loss: 0.9546 - val_accuracy: 0.6800\n",
      "Epoch 539/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7321 - accuracy: 0.7222 - val_loss: 0.9538 - val_accuracy: 0.6735\n",
      "Epoch 540/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7212 - accuracy: 0.7277 - val_loss: 0.9761 - val_accuracy: 0.6682\n",
      "Epoch 541/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7288 - accuracy: 0.7255 - val_loss: 0.9538 - val_accuracy: 0.6685\n",
      "Epoch 542/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7260 - accuracy: 0.7238 - val_loss: 0.9525 - val_accuracy: 0.6733\n",
      "Epoch 543/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7234 - accuracy: 0.7260 - val_loss: 0.9754 - val_accuracy: 0.6715\n",
      "Epoch 544/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7320 - accuracy: 0.7220 - val_loss: 0.9525 - val_accuracy: 0.6764\n",
      "Epoch 545/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.7238 - val_loss: 0.9662 - val_accuracy: 0.6653\n",
      "Epoch 546/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7269 - accuracy: 0.7248 - val_loss: 0.9544 - val_accuracy: 0.6717\n",
      "Epoch 547/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7167 - accuracy: 0.7276 - val_loss: 0.9592 - val_accuracy: 0.6761\n",
      "Epoch 548/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7257 - accuracy: 0.7260 - val_loss: 0.9606 - val_accuracy: 0.6747\n",
      "Epoch 549/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7263 - accuracy: 0.7266 - val_loss: 0.9693 - val_accuracy: 0.6746\n",
      "Epoch 550/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7211 - accuracy: 0.7265 - val_loss: 0.9501 - val_accuracy: 0.6732\n",
      "Epoch 551/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7298 - accuracy: 0.7249 - val_loss: 0.9599 - val_accuracy: 0.6778\n",
      "Epoch 552/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7189 - accuracy: 0.7274 - val_loss: 0.9640 - val_accuracy: 0.6718\n",
      "Epoch 553/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7170 - accuracy: 0.7286 - val_loss: 0.9646 - val_accuracy: 0.6746\n",
      "Epoch 554/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7253 - accuracy: 0.7223 - val_loss: 0.9654 - val_accuracy: 0.6726\n",
      "Epoch 555/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7259 - accuracy: 0.7244 - val_loss: 0.9577 - val_accuracy: 0.6796\n",
      "Epoch 556/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7152 - accuracy: 0.7294 - val_loss: 0.9729 - val_accuracy: 0.6669\n",
      "Epoch 557/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7215 - accuracy: 0.7273 - val_loss: 0.9739 - val_accuracy: 0.6739\n",
      "Epoch 558/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7236 - accuracy: 0.7267 - val_loss: 0.9564 - val_accuracy: 0.6782\n",
      "Epoch 559/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7242 - accuracy: 0.7261 - val_loss: 0.9808 - val_accuracy: 0.6687\n",
      "Epoch 560/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7320 - accuracy: 0.7243 - val_loss: 0.9699 - val_accuracy: 0.6729\n",
      "Epoch 561/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7197 - accuracy: 0.7286 - val_loss: 0.9838 - val_accuracy: 0.6674\n",
      "Epoch 562/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7208 - accuracy: 0.7294 - val_loss: 0.9670 - val_accuracy: 0.6747\n",
      "Epoch 563/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7230 - accuracy: 0.7286 - val_loss: 0.9777 - val_accuracy: 0.6707\n",
      "Epoch 564/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7175 - accuracy: 0.7293 - val_loss: 0.9773 - val_accuracy: 0.6714\n",
      "Epoch 565/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7274 - accuracy: 0.7242 - val_loss: 0.9664 - val_accuracy: 0.6725\n",
      "Epoch 566/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7192 - accuracy: 0.7284 - val_loss: 0.9856 - val_accuracy: 0.6733\n",
      "Epoch 567/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7233 - accuracy: 0.7250 - val_loss: 0.9501 - val_accuracy: 0.6810\n",
      "Epoch 568/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7244 - accuracy: 0.7236 - val_loss: 0.9822 - val_accuracy: 0.6701\n",
      "Epoch 569/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7225 - accuracy: 0.7273 - val_loss: 0.9711 - val_accuracy: 0.6728\n",
      "Epoch 570/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7250 - accuracy: 0.7248 - val_loss: 0.9633 - val_accuracy: 0.6706\n",
      "Epoch 571/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7181 - accuracy: 0.7280 - val_loss: 0.9833 - val_accuracy: 0.6771\n",
      "Epoch 572/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7189 - accuracy: 0.7268 - val_loss: 0.9543 - val_accuracy: 0.6762\n",
      "Epoch 573/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7239 - accuracy: 0.7251 - val_loss: 0.9641 - val_accuracy: 0.6732\n",
      "Epoch 574/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7258 - val_loss: 0.9644 - val_accuracy: 0.6782\n",
      "Epoch 575/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7223 - accuracy: 0.7261 - val_loss: 0.9716 - val_accuracy: 0.6778\n",
      "Epoch 576/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7167 - accuracy: 0.7290 - val_loss: 0.9641 - val_accuracy: 0.6722\n",
      "Epoch 577/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7267 - accuracy: 0.7259 - val_loss: 0.9637 - val_accuracy: 0.6715\n",
      "Epoch 578/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7201 - accuracy: 0.7269 - val_loss: 0.9526 - val_accuracy: 0.6815\n",
      "Epoch 579/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7220 - accuracy: 0.7264 - val_loss: 0.9715 - val_accuracy: 0.6769\n",
      "Epoch 580/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7255 - accuracy: 0.7245 - val_loss: 0.9684 - val_accuracy: 0.6735\n",
      "Epoch 581/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7149 - accuracy: 0.7311 - val_loss: 0.9794 - val_accuracy: 0.6683\n",
      "Epoch 582/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7177 - accuracy: 0.7272 - val_loss: 0.9786 - val_accuracy: 0.6731\n",
      "Epoch 583/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7239 - accuracy: 0.7256 - val_loss: 0.9696 - val_accuracy: 0.6742\n",
      "Epoch 584/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7170 - accuracy: 0.7317 - val_loss: 0.9547 - val_accuracy: 0.6764\n",
      "Epoch 585/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7161 - accuracy: 0.7294 - val_loss: 0.9807 - val_accuracy: 0.6690\n",
      "Epoch 586/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7214 - accuracy: 0.7263 - val_loss: 0.9516 - val_accuracy: 0.6775\n",
      "Epoch 587/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7145 - accuracy: 0.7282 - val_loss: 0.9664 - val_accuracy: 0.6797\n",
      "Epoch 588/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7193 - accuracy: 0.7263 - val_loss: 0.9768 - val_accuracy: 0.6728\n",
      "Epoch 589/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7202 - accuracy: 0.7268 - val_loss: 0.9706 - val_accuracy: 0.6783\n",
      "Epoch 590/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7163 - accuracy: 0.7264 - val_loss: 0.9730 - val_accuracy: 0.6762\n",
      "Epoch 591/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7128 - accuracy: 0.7283 - val_loss: 0.9834 - val_accuracy: 0.6747\n",
      "Epoch 592/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7207 - accuracy: 0.7277 - val_loss: 0.9622 - val_accuracy: 0.6797\n",
      "Epoch 593/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7190 - accuracy: 0.7276 - val_loss: 0.9735 - val_accuracy: 0.6715\n",
      "Epoch 594/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7245 - accuracy: 0.7237 - val_loss: 0.9465 - val_accuracy: 0.6812\n",
      "Epoch 595/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7109 - accuracy: 0.7328 - val_loss: 0.9880 - val_accuracy: 0.6626\n",
      "Epoch 596/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7151 - accuracy: 0.7281 - val_loss: 0.9736 - val_accuracy: 0.6782\n",
      "Epoch 597/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7122 - accuracy: 0.7278 - val_loss: 0.9644 - val_accuracy: 0.6654\n",
      "Epoch 598/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7221 - accuracy: 0.7290 - val_loss: 0.9686 - val_accuracy: 0.6753\n",
      "Epoch 599/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7223 - accuracy: 0.7275 - val_loss: 0.9540 - val_accuracy: 0.6807\n",
      "Epoch 600/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7139 - accuracy: 0.7276 - val_loss: 0.9625 - val_accuracy: 0.6694\n",
      "Epoch 601/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7167 - accuracy: 0.7261 - val_loss: 0.9633 - val_accuracy: 0.6771\n",
      "Epoch 602/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7168 - accuracy: 0.7281 - val_loss: 0.9835 - val_accuracy: 0.6742\n",
      "Epoch 603/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7154 - accuracy: 0.7309 - val_loss: 0.9846 - val_accuracy: 0.6718\n",
      "Epoch 604/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7144 - accuracy: 0.7291 - val_loss: 0.9643 - val_accuracy: 0.6761\n",
      "Epoch 605/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7201 - accuracy: 0.7306 - val_loss: 0.9634 - val_accuracy: 0.6803\n",
      "Epoch 606/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7163 - accuracy: 0.7291 - val_loss: 0.9754 - val_accuracy: 0.6712\n",
      "Epoch 607/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7122 - accuracy: 0.7290 - val_loss: 0.9633 - val_accuracy: 0.6767\n",
      "Epoch 608/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7145 - accuracy: 0.7309 - val_loss: 0.9660 - val_accuracy: 0.6700\n",
      "Epoch 609/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7154 - accuracy: 0.7270 - val_loss: 0.9681 - val_accuracy: 0.6801\n",
      "Epoch 610/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7070 - accuracy: 0.7360 - val_loss: 0.9670 - val_accuracy: 0.6722\n",
      "Epoch 611/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7153 - accuracy: 0.7308 - val_loss: 0.9774 - val_accuracy: 0.6675\n",
      "Epoch 612/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7145 - accuracy: 0.7276 - val_loss: 0.9679 - val_accuracy: 0.6778\n",
      "Epoch 613/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7128 - accuracy: 0.7327 - val_loss: 0.9575 - val_accuracy: 0.6822\n",
      "Epoch 614/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7189 - accuracy: 0.7288 - val_loss: 0.9938 - val_accuracy: 0.6637\n",
      "Epoch 615/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7187 - accuracy: 0.7273 - val_loss: 0.9689 - val_accuracy: 0.6733\n",
      "Epoch 616/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7163 - accuracy: 0.7279 - val_loss: 0.9617 - val_accuracy: 0.6757\n",
      "Epoch 617/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7106 - accuracy: 0.7336 - val_loss: 0.9688 - val_accuracy: 0.6762\n",
      "Epoch 618/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7106 - accuracy: 0.7319 - val_loss: 0.9774 - val_accuracy: 0.6694\n",
      "Epoch 619/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7175 - accuracy: 0.7284 - val_loss: 0.9672 - val_accuracy: 0.6764\n",
      "Epoch 620/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7083 - accuracy: 0.7324 - val_loss: 0.9819 - val_accuracy: 0.6737\n",
      "Epoch 621/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7270 - accuracy: 0.7236 - val_loss: 0.9601 - val_accuracy: 0.6761\n",
      "Epoch 622/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7126 - accuracy: 0.7292 - val_loss: 0.9635 - val_accuracy: 0.6697\n",
      "Epoch 623/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7095 - accuracy: 0.7302 - val_loss: 0.9890 - val_accuracy: 0.6671\n",
      "Epoch 624/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7098 - accuracy: 0.7309 - val_loss: 0.9794 - val_accuracy: 0.6710\n",
      "Epoch 625/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7103 - accuracy: 0.7310 - val_loss: 0.9750 - val_accuracy: 0.6756\n",
      "Epoch 626/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7102 - accuracy: 0.7331 - val_loss: 0.9792 - val_accuracy: 0.6721\n",
      "Epoch 627/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7046 - accuracy: 0.7315 - val_loss: 0.9887 - val_accuracy: 0.6753\n",
      "Epoch 628/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7167 - accuracy: 0.7303 - val_loss: 0.9678 - val_accuracy: 0.6796\n",
      "Epoch 629/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7045 - accuracy: 0.7323 - val_loss: 0.9759 - val_accuracy: 0.6701\n",
      "Epoch 630/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7118 - accuracy: 0.7305 - val_loss: 0.9605 - val_accuracy: 0.6715\n",
      "Epoch 631/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7078 - accuracy: 0.7326 - val_loss: 0.9889 - val_accuracy: 0.6704\n",
      "Epoch 632/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7112 - accuracy: 0.7334 - val_loss: 0.9799 - val_accuracy: 0.6728\n",
      "Epoch 633/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7090 - accuracy: 0.7308 - val_loss: 0.9607 - val_accuracy: 0.6810\n",
      "Epoch 634/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7013 - accuracy: 0.7344 - val_loss: 0.9731 - val_accuracy: 0.6785\n",
      "Epoch 635/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7054 - accuracy: 0.7291 - val_loss: 0.9813 - val_accuracy: 0.6782\n",
      "Epoch 636/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7108 - accuracy: 0.7315 - val_loss: 0.9649 - val_accuracy: 0.6753\n",
      "Epoch 637/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7117 - accuracy: 0.7308 - val_loss: 0.9758 - val_accuracy: 0.6785\n",
      "Epoch 638/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7169 - accuracy: 0.7282 - val_loss: 0.9752 - val_accuracy: 0.6751\n",
      "Epoch 639/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7117 - accuracy: 0.7302 - val_loss: 0.9984 - val_accuracy: 0.6753\n",
      "Epoch 640/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7042 - accuracy: 0.7315 - val_loss: 0.9665 - val_accuracy: 0.6806\n",
      "Epoch 641/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7124 - accuracy: 0.7313 - val_loss: 0.9609 - val_accuracy: 0.6781\n",
      "Epoch 642/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7105 - accuracy: 0.7324 - val_loss: 0.9528 - val_accuracy: 0.6810\n",
      "Epoch 643/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7044 - accuracy: 0.7346 - val_loss: 0.9802 - val_accuracy: 0.6754\n",
      "Epoch 644/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7079 - accuracy: 0.7313 - val_loss: 0.9691 - val_accuracy: 0.6822\n",
      "Epoch 645/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7079 - accuracy: 0.7333 - val_loss: 0.9829 - val_accuracy: 0.6743\n",
      "Epoch 646/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7120 - accuracy: 0.7292 - val_loss: 0.9656 - val_accuracy: 0.6753\n",
      "Epoch 647/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7123 - accuracy: 0.7289 - val_loss: 0.9748 - val_accuracy: 0.6733\n",
      "Epoch 648/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7061 - accuracy: 0.7335 - val_loss: 0.9802 - val_accuracy: 0.6779\n",
      "Epoch 649/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7088 - accuracy: 0.7320 - val_loss: 0.9703 - val_accuracy: 0.6737\n",
      "Epoch 650/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7101 - accuracy: 0.7320 - val_loss: 0.9594 - val_accuracy: 0.6796\n",
      "Epoch 651/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7003 - accuracy: 0.7346 - val_loss: 0.9715 - val_accuracy: 0.6831\n",
      "Epoch 652/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7068 - accuracy: 0.7323 - val_loss: 0.9629 - val_accuracy: 0.6806\n",
      "Epoch 653/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7123 - accuracy: 0.7291 - val_loss: 0.9658 - val_accuracy: 0.6757\n",
      "Epoch 654/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7004 - accuracy: 0.7359 - val_loss: 0.9748 - val_accuracy: 0.6819\n",
      "Epoch 655/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7074 - accuracy: 0.7307 - val_loss: 0.9609 - val_accuracy: 0.6800\n",
      "Epoch 656/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7082 - accuracy: 0.7314 - val_loss: 0.9741 - val_accuracy: 0.6746\n",
      "Epoch 657/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7101 - accuracy: 0.7301 - val_loss: 0.9803 - val_accuracy: 0.6708\n",
      "Epoch 658/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7019 - accuracy: 0.7320 - val_loss: 0.9759 - val_accuracy: 0.6781\n",
      "Epoch 659/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7046 - accuracy: 0.7344 - val_loss: 0.9646 - val_accuracy: 0.6815\n",
      "Epoch 660/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7113 - accuracy: 0.7306 - val_loss: 0.9675 - val_accuracy: 0.6776\n",
      "Epoch 661/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7062 - accuracy: 0.7341 - val_loss: 0.9586 - val_accuracy: 0.6849\n",
      "Epoch 662/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7066 - accuracy: 0.7308 - val_loss: 0.9717 - val_accuracy: 0.6790\n",
      "Epoch 663/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7033 - accuracy: 0.7336 - val_loss: 0.9762 - val_accuracy: 0.6743\n",
      "Epoch 664/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7098 - accuracy: 0.7312 - val_loss: 0.9731 - val_accuracy: 0.6787\n",
      "Epoch 665/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7025 - accuracy: 0.7327 - val_loss: 0.9818 - val_accuracy: 0.6762\n",
      "Epoch 666/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7084 - accuracy: 0.7310 - val_loss: 0.9687 - val_accuracy: 0.6760\n",
      "Epoch 667/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7038 - accuracy: 0.7340 - val_loss: 0.9613 - val_accuracy: 0.6771\n",
      "Epoch 668/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7055 - accuracy: 0.7352 - val_loss: 0.9674 - val_accuracy: 0.6814\n",
      "Epoch 669/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7030 - accuracy: 0.7339 - val_loss: 0.9880 - val_accuracy: 0.6746\n",
      "Epoch 670/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7118 - accuracy: 0.7299 - val_loss: 0.9560 - val_accuracy: 0.6867\n",
      "Epoch 671/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7028 - accuracy: 0.7376 - val_loss: 0.9694 - val_accuracy: 0.6764\n",
      "Epoch 672/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7121 - accuracy: 0.7314 - val_loss: 0.9625 - val_accuracy: 0.6801\n",
      "Epoch 673/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7039 - accuracy: 0.7335 - val_loss: 0.9743 - val_accuracy: 0.6768\n",
      "Epoch 674/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7089 - accuracy: 0.7288 - val_loss: 0.9688 - val_accuracy: 0.6782\n",
      "Epoch 675/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7079 - accuracy: 0.7310 - val_loss: 0.9752 - val_accuracy: 0.6746\n",
      "Epoch 676/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7057 - accuracy: 0.7337 - val_loss: 0.9614 - val_accuracy: 0.6799\n",
      "Epoch 677/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7089 - accuracy: 0.7329 - val_loss: 0.9753 - val_accuracy: 0.6742\n",
      "Epoch 678/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7081 - accuracy: 0.7335 - val_loss: 0.9691 - val_accuracy: 0.6783\n",
      "Epoch 679/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7098 - accuracy: 0.7294 - val_loss: 0.9574 - val_accuracy: 0.6810\n",
      "Epoch 680/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7012 - accuracy: 0.7322 - val_loss: 0.9679 - val_accuracy: 0.6776\n",
      "Epoch 681/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7095 - accuracy: 0.7317 - val_loss: 0.9760 - val_accuracy: 0.6765\n",
      "Epoch 682/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7003 - accuracy: 0.7328 - val_loss: 0.9680 - val_accuracy: 0.6804\n",
      "Epoch 683/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6999 - accuracy: 0.7344 - val_loss: 0.9881 - val_accuracy: 0.6707\n",
      "Epoch 684/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7035 - accuracy: 0.7342 - val_loss: 0.9572 - val_accuracy: 0.6792\n",
      "Epoch 685/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7046 - accuracy: 0.7342 - val_loss: 0.9965 - val_accuracy: 0.6693\n",
      "Epoch 686/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7036 - accuracy: 0.7348 - val_loss: 0.9625 - val_accuracy: 0.6869\n",
      "Epoch 687/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7081 - accuracy: 0.7325 - val_loss: 0.9536 - val_accuracy: 0.6828\n",
      "Epoch 688/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7030 - accuracy: 0.7347 - val_loss: 0.9831 - val_accuracy: 0.6692\n",
      "Epoch 689/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7059 - accuracy: 0.7343 - val_loss: 0.9603 - val_accuracy: 0.6762\n",
      "Epoch 690/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6975 - accuracy: 0.7352 - val_loss: 0.9686 - val_accuracy: 0.6778\n",
      "Epoch 691/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6987 - accuracy: 0.7367 - val_loss: 0.9774 - val_accuracy: 0.6775\n",
      "Epoch 692/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6986 - accuracy: 0.7340 - val_loss: 0.9632 - val_accuracy: 0.6814\n",
      "Epoch 693/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7058 - accuracy: 0.7323 - val_loss: 0.9636 - val_accuracy: 0.6736\n",
      "Epoch 694/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6991 - accuracy: 0.7366 - val_loss: 0.9622 - val_accuracy: 0.6860\n",
      "Epoch 695/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.7370 - val_loss: 0.9591 - val_accuracy: 0.6875\n",
      "Epoch 696/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7052 - accuracy: 0.7318 - val_loss: 0.9980 - val_accuracy: 0.6719\n",
      "Epoch 697/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7047 - accuracy: 0.7338 - val_loss: 0.9609 - val_accuracy: 0.6851\n",
      "Epoch 698/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7051 - accuracy: 0.7327 - val_loss: 0.9635 - val_accuracy: 0.6767\n",
      "Epoch 699/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7017 - accuracy: 0.7343 - val_loss: 0.9761 - val_accuracy: 0.6706\n",
      "Epoch 700/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7016 - accuracy: 0.7339 - val_loss: 0.9961 - val_accuracy: 0.6708\n",
      "Epoch 701/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7047 - accuracy: 0.7333 - val_loss: 0.9640 - val_accuracy: 0.6797\n",
      "Epoch 702/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7035 - accuracy: 0.7344 - val_loss: 0.9710 - val_accuracy: 0.6786\n",
      "Epoch 703/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6979 - accuracy: 0.7378 - val_loss: 0.9617 - val_accuracy: 0.6819\n",
      "Epoch 704/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7009 - accuracy: 0.7346 - val_loss: 0.9690 - val_accuracy: 0.6821\n",
      "Epoch 705/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7020 - accuracy: 0.7332 - val_loss: 0.9693 - val_accuracy: 0.6764\n",
      "Epoch 706/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7007 - accuracy: 0.7352 - val_loss: 0.9662 - val_accuracy: 0.6801\n",
      "Epoch 707/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7041 - accuracy: 0.7318 - val_loss: 0.9800 - val_accuracy: 0.6735\n",
      "Epoch 708/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.7394 - val_loss: 0.9645 - val_accuracy: 0.6796\n",
      "Epoch 709/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6999 - accuracy: 0.7311 - val_loss: 0.9846 - val_accuracy: 0.6700\n",
      "Epoch 710/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7003 - accuracy: 0.7337 - val_loss: 0.9845 - val_accuracy: 0.6811\n",
      "Epoch 711/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7065 - accuracy: 0.7323 - val_loss: 0.9654 - val_accuracy: 0.6832\n",
      "Epoch 712/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6973 - accuracy: 0.7381 - val_loss: 0.9787 - val_accuracy: 0.6815\n",
      "Epoch 713/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6968 - accuracy: 0.7328 - val_loss: 0.9738 - val_accuracy: 0.6749\n",
      "Epoch 714/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6994 - accuracy: 0.7344 - val_loss: 0.9594 - val_accuracy: 0.6851\n",
      "Epoch 715/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6941 - accuracy: 0.7367 - val_loss: 0.9719 - val_accuracy: 0.6757\n",
      "Epoch 716/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6952 - accuracy: 0.7358 - val_loss: 0.9648 - val_accuracy: 0.6783\n",
      "Epoch 717/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7015 - accuracy: 0.7365 - val_loss: 0.9910 - val_accuracy: 0.6653\n",
      "Epoch 718/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7049 - accuracy: 0.7339 - val_loss: 0.9930 - val_accuracy: 0.6679\n",
      "Epoch 719/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7038 - accuracy: 0.7355 - val_loss: 0.9619 - val_accuracy: 0.6812\n",
      "Epoch 720/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.7043 - accuracy: 0.7342 - val_loss: 0.9745 - val_accuracy: 0.6801\n",
      "Epoch 721/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6965 - accuracy: 0.7350 - val_loss: 0.9748 - val_accuracy: 0.6765\n",
      "Epoch 722/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7046 - accuracy: 0.7337 - val_loss: 0.9772 - val_accuracy: 0.6732\n",
      "Epoch 723/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7020 - accuracy: 0.7361 - val_loss: 0.9716 - val_accuracy: 0.6826\n",
      "Epoch 724/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7072 - accuracy: 0.7306 - val_loss: 0.9638 - val_accuracy: 0.6878\n",
      "Epoch 725/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 0.7010 - accuracy: 0.7334 - val_loss: 0.9772 - val_accuracy: 0.6714\n",
      "Epoch 726/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6988 - accuracy: 0.7330 - val_loss: 0.9767 - val_accuracy: 0.6779\n",
      "Epoch 727/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 0.6948 - accuracy: 0.7369 - val_loss: 0.9732 - val_accuracy: 0.6772\n",
      "Epoch 728/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.7352 - val_loss: 0.9644 - val_accuracy: 0.6843\n",
      "Epoch 729/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7081 - accuracy: 0.7322 - val_loss: 0.9606 - val_accuracy: 0.6794\n",
      "Epoch 730/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7012 - accuracy: 0.7355 - val_loss: 0.9669 - val_accuracy: 0.6790\n",
      "Epoch 731/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.7374 - val_loss: 0.9852 - val_accuracy: 0.6718\n",
      "Epoch 732/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7063 - accuracy: 0.7337 - val_loss: 0.9708 - val_accuracy: 0.6811\n",
      "Epoch 733/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7028 - accuracy: 0.7348 - val_loss: 0.9730 - val_accuracy: 0.6792\n",
      "Epoch 734/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.7336 - val_loss: 0.9669 - val_accuracy: 0.6835\n",
      "Epoch 735/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.7395 - val_loss: 0.9779 - val_accuracy: 0.6772\n",
      "Epoch 736/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7063 - accuracy: 0.7319 - val_loss: 0.9815 - val_accuracy: 0.6801\n",
      "Epoch 737/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.7332 - val_loss: 0.9874 - val_accuracy: 0.6804\n",
      "Epoch 738/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.7354 - val_loss: 0.9704 - val_accuracy: 0.6801\n",
      "Epoch 739/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6948 - accuracy: 0.7366 - val_loss: 0.9980 - val_accuracy: 0.6750\n",
      "Epoch 740/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6990 - accuracy: 0.7366 - val_loss: 0.9583 - val_accuracy: 0.6858\n",
      "Epoch 741/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6967 - accuracy: 0.7362 - val_loss: 0.9825 - val_accuracy: 0.6789\n",
      "Epoch 742/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7015 - accuracy: 0.7359 - val_loss: 0.9520 - val_accuracy: 0.6861\n",
      "Epoch 743/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.7364 - val_loss: 0.9763 - val_accuracy: 0.6804\n",
      "Epoch 744/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6960 - accuracy: 0.7357 - val_loss: 0.9629 - val_accuracy: 0.6843\n",
      "Epoch 745/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.7389 - val_loss: 0.9657 - val_accuracy: 0.6786\n",
      "Epoch 746/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6946 - accuracy: 0.7376 - val_loss: 0.9617 - val_accuracy: 0.6847\n",
      "Epoch 747/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.7400 - val_loss: 0.9707 - val_accuracy: 0.6843\n",
      "Epoch 748/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.7395 - val_loss: 0.9624 - val_accuracy: 0.6839\n",
      "Epoch 749/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6986 - accuracy: 0.7350 - val_loss: 0.9615 - val_accuracy: 0.6837\n",
      "Epoch 750/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6975 - accuracy: 0.7383 - val_loss: 0.9854 - val_accuracy: 0.6757\n",
      "Epoch 751/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7038 - accuracy: 0.7333 - val_loss: 0.9745 - val_accuracy: 0.6821\n",
      "Epoch 752/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.7376 - val_loss: 0.9731 - val_accuracy: 0.6808\n",
      "Epoch 753/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.7385 - val_loss: 0.9548 - val_accuracy: 0.6864\n",
      "Epoch 754/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6989 - accuracy: 0.7373 - val_loss: 0.9691 - val_accuracy: 0.6767\n",
      "Epoch 755/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.7383 - val_loss: 0.9689 - val_accuracy: 0.6804\n",
      "Epoch 756/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.7381 - val_loss: 0.9635 - val_accuracy: 0.6786\n",
      "Epoch 757/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.7383 - val_loss: 0.9604 - val_accuracy: 0.6839\n",
      "Epoch 758/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7030 - accuracy: 0.7340 - val_loss: 0.9805 - val_accuracy: 0.6835\n",
      "Epoch 759/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6964 - accuracy: 0.7355 - val_loss: 0.9725 - val_accuracy: 0.6847\n",
      "Epoch 760/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.7404 - val_loss: 0.9524 - val_accuracy: 0.6886\n",
      "Epoch 761/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.7341 - val_loss: 0.9616 - val_accuracy: 0.6826\n",
      "Epoch 762/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.7396 - val_loss: 0.9717 - val_accuracy: 0.6794\n",
      "Epoch 763/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6974 - accuracy: 0.7372 - val_loss: 0.9634 - val_accuracy: 0.6833\n",
      "Epoch 764/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7030 - accuracy: 0.7366 - val_loss: 0.9516 - val_accuracy: 0.6878\n",
      "Epoch 765/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6992 - accuracy: 0.7360 - val_loss: 0.9844 - val_accuracy: 0.6750\n",
      "Epoch 766/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6960 - accuracy: 0.7386 - val_loss: 0.9581 - val_accuracy: 0.6865\n",
      "Epoch 767/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.7372 - val_loss: 0.9778 - val_accuracy: 0.6774\n",
      "Epoch 768/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7034 - accuracy: 0.7333 - val_loss: 0.9775 - val_accuracy: 0.6832\n",
      "Epoch 769/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.7010 - accuracy: 0.7365 - val_loss: 0.9930 - val_accuracy: 0.6731\n",
      "Epoch 770/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.7379 - val_loss: 0.9705 - val_accuracy: 0.6818\n",
      "Epoch 771/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6995 - accuracy: 0.7349 - val_loss: 0.9606 - val_accuracy: 0.6812\n",
      "Epoch 772/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6871 - accuracy: 0.7412 - val_loss: 0.9709 - val_accuracy: 0.6836\n",
      "Epoch 773/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.7369 - val_loss: 0.9798 - val_accuracy: 0.6782\n",
      "Epoch 774/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.7368 - val_loss: 0.9665 - val_accuracy: 0.6835\n",
      "Epoch 775/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6983 - accuracy: 0.7397 - val_loss: 0.9547 - val_accuracy: 0.6851\n",
      "Epoch 776/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.7403 - val_loss: 0.9694 - val_accuracy: 0.6865\n",
      "Epoch 777/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6965 - accuracy: 0.7350 - val_loss: 0.9659 - val_accuracy: 0.6822\n",
      "Epoch 778/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.7340 - val_loss: 0.9819 - val_accuracy: 0.6821\n",
      "Epoch 779/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.7400 - val_loss: 0.9713 - val_accuracy: 0.6840\n",
      "Epoch 780/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.7360 - val_loss: 0.9677 - val_accuracy: 0.6824\n",
      "Epoch 781/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.7380 - val_loss: 0.9632 - val_accuracy: 0.6793\n",
      "Epoch 782/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6937 - accuracy: 0.7393 - val_loss: 0.9578 - val_accuracy: 0.6847\n",
      "Epoch 783/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.7380 - val_loss: 0.9622 - val_accuracy: 0.6886\n",
      "Epoch 784/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.7395 - val_loss: 0.9655 - val_accuracy: 0.6844\n",
      "Epoch 785/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.7394 - val_loss: 0.9645 - val_accuracy: 0.6843\n",
      "Epoch 786/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.7370 - val_loss: 0.9696 - val_accuracy: 0.6878\n",
      "Epoch 787/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.7385 - val_loss: 0.9864 - val_accuracy: 0.6785\n",
      "Epoch 788/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.7412 - val_loss: 0.9670 - val_accuracy: 0.6803\n",
      "Epoch 789/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6917 - accuracy: 0.7387 - val_loss: 0.9611 - val_accuracy: 0.6892\n",
      "Epoch 790/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.7390 - val_loss: 0.9833 - val_accuracy: 0.6783\n",
      "Epoch 791/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6901 - accuracy: 0.7394 - val_loss: 0.9876 - val_accuracy: 0.6786\n",
      "Epoch 792/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.7399 - val_loss: 0.9654 - val_accuracy: 0.6869\n",
      "Epoch 793/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6970 - accuracy: 0.7372 - val_loss: 0.9584 - val_accuracy: 0.6821\n",
      "Epoch 794/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6935 - accuracy: 0.7374 - val_loss: 0.9691 - val_accuracy: 0.6829\n",
      "Epoch 795/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.7005 - accuracy: 0.7355 - val_loss: 0.9866 - val_accuracy: 0.6764\n",
      "Epoch 796/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6892 - accuracy: 0.7415 - val_loss: 0.9764 - val_accuracy: 0.6892\n",
      "Epoch 797/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.7359 - val_loss: 0.9595 - val_accuracy: 0.6865\n",
      "Epoch 798/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.7397 - val_loss: 0.9557 - val_accuracy: 0.6874\n",
      "Epoch 799/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.7383 - val_loss: 0.9722 - val_accuracy: 0.6846\n",
      "Epoch 800/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.7351 - val_loss: 0.9599 - val_accuracy: 0.6861\n",
      "Epoch 801/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.7367 - val_loss: 0.9716 - val_accuracy: 0.6906\n",
      "Epoch 802/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6954 - accuracy: 0.7364 - val_loss: 0.9615 - val_accuracy: 0.6844\n",
      "Epoch 803/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.7374 - val_loss: 0.9707 - val_accuracy: 0.6854\n",
      "Epoch 804/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.7382 - val_loss: 0.9774 - val_accuracy: 0.6800\n",
      "Epoch 805/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.7388 - val_loss: 0.9624 - val_accuracy: 0.6872\n",
      "Epoch 806/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.7402 - val_loss: 0.9582 - val_accuracy: 0.6819\n",
      "Epoch 807/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6917 - accuracy: 0.7392 - val_loss: 0.9795 - val_accuracy: 0.6783\n",
      "Epoch 808/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6915 - accuracy: 0.7379 - val_loss: 0.9594 - val_accuracy: 0.6869\n",
      "Epoch 809/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.7394 - val_loss: 0.9766 - val_accuracy: 0.6840\n",
      "Epoch 810/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.7380 - val_loss: 0.9837 - val_accuracy: 0.6786\n",
      "Epoch 811/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.7372 - val_loss: 0.9836 - val_accuracy: 0.6729\n",
      "Epoch 812/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.7387 - val_loss: 0.9705 - val_accuracy: 0.6846\n",
      "Epoch 813/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.7413 - val_loss: 0.9643 - val_accuracy: 0.6811\n",
      "Epoch 814/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.7376 - val_loss: 0.9880 - val_accuracy: 0.6785\n",
      "Epoch 815/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.7378 - val_loss: 0.9491 - val_accuracy: 0.6867\n",
      "Epoch 816/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6922 - accuracy: 0.7399 - val_loss: 0.9892 - val_accuracy: 0.6778\n",
      "Epoch 817/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.7396 - val_loss: 0.9540 - val_accuracy: 0.6911\n",
      "Epoch 818/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6851 - accuracy: 0.7403 - val_loss: 0.9726 - val_accuracy: 0.6851\n",
      "Epoch 819/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.7406 - val_loss: 0.9619 - val_accuracy: 0.6839\n",
      "Epoch 820/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6857 - accuracy: 0.7401 - val_loss: 0.9576 - val_accuracy: 0.6878\n",
      "Epoch 821/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.7393 - val_loss: 0.9776 - val_accuracy: 0.6811\n",
      "Epoch 822/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.7386 - val_loss: 0.9753 - val_accuracy: 0.6792\n",
      "Epoch 823/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6885 - accuracy: 0.7407 - val_loss: 0.9710 - val_accuracy: 0.6892\n",
      "Epoch 824/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.7376 - val_loss: 0.9781 - val_accuracy: 0.6814\n",
      "Epoch 825/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.7397 - val_loss: 0.9783 - val_accuracy: 0.6776\n",
      "Epoch 826/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.7440 - val_loss: 1.0355 - val_accuracy: 0.6646\n",
      "Epoch 827/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6875 - accuracy: 0.7417 - val_loss: 0.9566 - val_accuracy: 0.6839\n",
      "Epoch 828/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.7403 - val_loss: 0.9937 - val_accuracy: 0.6785\n",
      "Epoch 829/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.7390 - val_loss: 0.9723 - val_accuracy: 0.6817\n",
      "Epoch 830/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6856 - accuracy: 0.7405 - val_loss: 0.9640 - val_accuracy: 0.6849\n",
      "Epoch 831/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.7375 - val_loss: 0.9863 - val_accuracy: 0.6854\n",
      "Epoch 832/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.7400 - val_loss: 1.0381 - val_accuracy: 0.6640\n",
      "Epoch 833/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.7402 - val_loss: 0.9706 - val_accuracy: 0.6801\n",
      "Epoch 834/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6828 - accuracy: 0.7433 - val_loss: 0.9811 - val_accuracy: 0.6757\n",
      "Epoch 835/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6850 - accuracy: 0.7417 - val_loss: 0.9736 - val_accuracy: 0.6810\n",
      "Epoch 836/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.7392 - val_loss: 0.9757 - val_accuracy: 0.6799\n",
      "Epoch 837/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6892 - accuracy: 0.7387 - val_loss: 0.9728 - val_accuracy: 0.6779\n",
      "Epoch 838/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.7428 - val_loss: 0.9741 - val_accuracy: 0.6864\n",
      "Epoch 839/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.7394 - val_loss: 0.9782 - val_accuracy: 0.6829\n",
      "Epoch 840/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6983 - accuracy: 0.7387 - val_loss: 0.9748 - val_accuracy: 0.6814\n",
      "Epoch 841/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.7386 - val_loss: 0.9612 - val_accuracy: 0.6857\n",
      "Epoch 842/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6867 - accuracy: 0.7402 - val_loss: 0.9829 - val_accuracy: 0.6812\n",
      "Epoch 843/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.7409 - val_loss: 0.9702 - val_accuracy: 0.6850\n",
      "Epoch 844/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.7393 - val_loss: 0.9478 - val_accuracy: 0.6892\n",
      "Epoch 845/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.7402 - val_loss: 0.9758 - val_accuracy: 0.6832\n",
      "Epoch 846/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.7398 - val_loss: 0.9716 - val_accuracy: 0.6833\n",
      "Epoch 847/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6823 - accuracy: 0.7414 - val_loss: 0.9725 - val_accuracy: 0.6846\n",
      "Epoch 848/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6850 - accuracy: 0.7405 - val_loss: 0.9621 - val_accuracy: 0.6861\n",
      "Epoch 849/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6906 - accuracy: 0.7392 - val_loss: 0.9890 - val_accuracy: 0.6824\n",
      "Epoch 850/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6830 - accuracy: 0.7406 - val_loss: 0.9784 - val_accuracy: 0.6843\n",
      "Epoch 851/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6895 - accuracy: 0.7408 - val_loss: 0.9662 - val_accuracy: 0.6869\n",
      "Epoch 852/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.7408 - val_loss: 0.9723 - val_accuracy: 0.6885\n",
      "Epoch 853/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.7387 - val_loss: 0.9699 - val_accuracy: 0.6824\n",
      "Epoch 854/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.7386 - val_loss: 0.9731 - val_accuracy: 0.6878\n",
      "Epoch 855/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.7404 - val_loss: 0.9755 - val_accuracy: 0.6854\n",
      "Epoch 856/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.7426 - val_loss: 0.9690 - val_accuracy: 0.6850\n",
      "Epoch 857/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6963 - accuracy: 0.7362 - val_loss: 0.9636 - val_accuracy: 0.6904\n",
      "Epoch 858/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.7418 - val_loss: 0.9782 - val_accuracy: 0.6821\n",
      "Epoch 859/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.7414 - val_loss: 0.9580 - val_accuracy: 0.6879\n",
      "Epoch 860/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.7397 - val_loss: 0.9798 - val_accuracy: 0.6857\n",
      "Epoch 861/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.7373 - val_loss: 0.9773 - val_accuracy: 0.6889\n",
      "Epoch 862/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.7406 - val_loss: 0.9710 - val_accuracy: 0.6860\n",
      "Epoch 863/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.7398 - val_loss: 0.9705 - val_accuracy: 0.6864\n",
      "Epoch 864/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6813 - accuracy: 0.7442 - val_loss: 0.9568 - val_accuracy: 0.6893\n",
      "Epoch 865/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.7376 - val_loss: 0.9670 - val_accuracy: 0.6810\n",
      "Epoch 866/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6935 - accuracy: 0.7378 - val_loss: 0.9666 - val_accuracy: 0.6872\n",
      "Epoch 867/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.7388 - val_loss: 0.9693 - val_accuracy: 0.6831\n",
      "Epoch 868/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6836 - accuracy: 0.7427 - val_loss: 0.9685 - val_accuracy: 0.6888\n",
      "Epoch 869/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6812 - accuracy: 0.7432 - val_loss: 0.9676 - val_accuracy: 0.6861\n",
      "Epoch 870/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.7402 - val_loss: 0.9845 - val_accuracy: 0.6735\n",
      "Epoch 871/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6840 - accuracy: 0.7418 - val_loss: 0.9910 - val_accuracy: 0.6808\n",
      "Epoch 872/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6794 - accuracy: 0.7426 - val_loss: 0.9636 - val_accuracy: 0.6901\n",
      "Epoch 873/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.7357 - val_loss: 0.9677 - val_accuracy: 0.6883\n",
      "Epoch 874/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.7392 - val_loss: 0.9750 - val_accuracy: 0.6886\n",
      "Epoch 875/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.7398 - val_loss: 0.9942 - val_accuracy: 0.6786\n",
      "Epoch 876/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6887 - accuracy: 0.7420 - val_loss: 0.9786 - val_accuracy: 0.6856\n",
      "Epoch 877/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6850 - accuracy: 0.7423 - val_loss: 0.9546 - val_accuracy: 0.6913\n",
      "Epoch 878/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6829 - accuracy: 0.7449 - val_loss: 0.9979 - val_accuracy: 0.6785\n",
      "Epoch 879/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6887 - accuracy: 0.7421 - val_loss: 0.9698 - val_accuracy: 0.6896\n",
      "Epoch 880/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6842 - accuracy: 0.7384 - val_loss: 0.9798 - val_accuracy: 0.6824\n",
      "Epoch 881/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.7404 - val_loss: 0.9611 - val_accuracy: 0.6908\n",
      "Epoch 882/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6847 - accuracy: 0.7445 - val_loss: 0.9602 - val_accuracy: 0.6883\n",
      "Epoch 883/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6798 - accuracy: 0.7405 - val_loss: 0.9645 - val_accuracy: 0.6824\n",
      "Epoch 884/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6825 - accuracy: 0.7425 - val_loss: 0.9704 - val_accuracy: 0.6906\n",
      "Epoch 885/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6795 - accuracy: 0.7439 - val_loss: 0.9701 - val_accuracy: 0.6826\n",
      "Epoch 886/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6799 - accuracy: 0.7414 - val_loss: 0.9679 - val_accuracy: 0.6849\n",
      "Epoch 887/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6837 - accuracy: 0.7429 - val_loss: 0.9719 - val_accuracy: 0.6803\n",
      "Epoch 888/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6878 - accuracy: 0.7416 - val_loss: 0.9924 - val_accuracy: 0.6793\n",
      "Epoch 889/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6805 - accuracy: 0.7422 - val_loss: 0.9688 - val_accuracy: 0.6883\n",
      "Epoch 890/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.7401 - val_loss: 0.9878 - val_accuracy: 0.6826\n",
      "Epoch 891/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6856 - accuracy: 0.7399 - val_loss: 0.9628 - val_accuracy: 0.6878\n",
      "Epoch 892/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6814 - accuracy: 0.7432 - val_loss: 0.9695 - val_accuracy: 0.6832\n",
      "Epoch 893/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6876 - accuracy: 0.7372 - val_loss: 0.9624 - val_accuracy: 0.6861\n",
      "Epoch 894/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.7447 - val_loss: 0.9583 - val_accuracy: 0.6921\n",
      "Epoch 895/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6828 - accuracy: 0.7423 - val_loss: 0.9584 - val_accuracy: 0.6842\n",
      "Epoch 896/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.7398 - val_loss: 0.9563 - val_accuracy: 0.6907\n",
      "Epoch 897/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.7429 - val_loss: 0.9647 - val_accuracy: 0.6882\n",
      "Epoch 898/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6814 - accuracy: 0.7435 - val_loss: 0.9581 - val_accuracy: 0.6883\n",
      "Epoch 899/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.7451 - val_loss: 0.9753 - val_accuracy: 0.6786\n",
      "Epoch 900/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6783 - accuracy: 0.7441 - val_loss: 0.9922 - val_accuracy: 0.6842\n",
      "Epoch 901/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.7393 - val_loss: 0.9741 - val_accuracy: 0.6896\n",
      "Epoch 902/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6810 - accuracy: 0.7440 - val_loss: 0.9707 - val_accuracy: 0.6851\n",
      "Epoch 903/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6861 - accuracy: 0.7409 - val_loss: 0.9726 - val_accuracy: 0.6867\n",
      "Epoch 904/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6713 - accuracy: 0.7470 - val_loss: 0.9640 - val_accuracy: 0.6911\n",
      "Epoch 905/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6801 - accuracy: 0.7426 - val_loss: 0.9677 - val_accuracy: 0.6844\n",
      "Epoch 906/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6791 - accuracy: 0.7419 - val_loss: 0.9563 - val_accuracy: 0.6929\n",
      "Epoch 907/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6805 - accuracy: 0.7406 - val_loss: 0.9738 - val_accuracy: 0.6824\n",
      "Epoch 908/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6754 - accuracy: 0.7441 - val_loss: 0.9751 - val_accuracy: 0.6903\n",
      "Epoch 909/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.7417 - val_loss: 0.9673 - val_accuracy: 0.6904\n",
      "Epoch 910/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6738 - accuracy: 0.7464 - val_loss: 0.9615 - val_accuracy: 0.6968\n",
      "Epoch 911/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.7411 - val_loss: 0.9660 - val_accuracy: 0.6844\n",
      "Epoch 912/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6818 - accuracy: 0.7422 - val_loss: 0.9609 - val_accuracy: 0.6888\n",
      "Epoch 913/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6800 - accuracy: 0.7415 - val_loss: 0.9591 - val_accuracy: 0.6925\n",
      "Epoch 914/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6742 - accuracy: 0.7456 - val_loss: 0.9756 - val_accuracy: 0.6867\n",
      "Epoch 915/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6851 - accuracy: 0.7410 - val_loss: 0.9828 - val_accuracy: 0.6846\n",
      "Epoch 916/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6740 - accuracy: 0.7458 - val_loss: 0.9626 - val_accuracy: 0.6862\n",
      "Epoch 917/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6744 - accuracy: 0.7457 - val_loss: 0.9651 - val_accuracy: 0.6876\n",
      "Epoch 918/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6783 - accuracy: 0.7442 - val_loss: 0.9718 - val_accuracy: 0.6876\n",
      "Epoch 919/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.7423 - val_loss: 0.9930 - val_accuracy: 0.6801\n",
      "Epoch 920/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6908 - accuracy: 0.7368 - val_loss: 0.9740 - val_accuracy: 0.6874\n",
      "Epoch 921/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6851 - accuracy: 0.7403 - val_loss: 0.9564 - val_accuracy: 0.6900\n",
      "Epoch 922/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6720 - accuracy: 0.7464 - val_loss: 0.9497 - val_accuracy: 0.6911\n",
      "Epoch 923/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6790 - accuracy: 0.7435 - val_loss: 0.9685 - val_accuracy: 0.6872\n",
      "Epoch 924/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6802 - accuracy: 0.7424 - val_loss: 0.9994 - val_accuracy: 0.6783\n",
      "Epoch 925/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6787 - accuracy: 0.7440 - val_loss: 0.9733 - val_accuracy: 0.6858\n",
      "Epoch 926/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6744 - accuracy: 0.7453 - val_loss: 0.9590 - val_accuracy: 0.6869\n",
      "Epoch 927/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6820 - accuracy: 0.7412 - val_loss: 0.9842 - val_accuracy: 0.6885\n",
      "Epoch 928/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6813 - accuracy: 0.7440 - val_loss: 0.9649 - val_accuracy: 0.6918\n",
      "Epoch 929/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6720 - accuracy: 0.7452 - val_loss: 0.9777 - val_accuracy: 0.6893\n",
      "Epoch 930/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6835 - accuracy: 0.7418 - val_loss: 0.9779 - val_accuracy: 0.6810\n",
      "Epoch 931/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6793 - accuracy: 0.7401 - val_loss: 0.9825 - val_accuracy: 0.6762\n",
      "Epoch 932/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6823 - accuracy: 0.7419 - val_loss: 0.9858 - val_accuracy: 0.6819\n",
      "Epoch 933/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6821 - accuracy: 0.7406 - val_loss: 0.9614 - val_accuracy: 0.6874\n",
      "Epoch 934/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6814 - accuracy: 0.7443 - val_loss: 0.9549 - val_accuracy: 0.6882\n",
      "Epoch 935/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6757 - accuracy: 0.7415 - val_loss: 0.9866 - val_accuracy: 0.6807\n",
      "Epoch 936/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6799 - accuracy: 0.7433 - val_loss: 0.9617 - val_accuracy: 0.6921\n",
      "Epoch 937/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6843 - accuracy: 0.7419 - val_loss: 0.9715 - val_accuracy: 0.6874\n",
      "Epoch 938/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.7455 - val_loss: 0.9677 - val_accuracy: 0.6875\n",
      "Epoch 939/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6784 - accuracy: 0.7427 - val_loss: 0.9646 - val_accuracy: 0.6829\n",
      "Epoch 940/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.7416 - val_loss: 0.9610 - val_accuracy: 0.6872\n",
      "Epoch 941/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.7395 - val_loss: 0.9445 - val_accuracy: 0.6986\n",
      "Epoch 942/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6734 - accuracy: 0.7440 - val_loss: 0.9550 - val_accuracy: 0.6951\n",
      "Epoch 943/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6833 - accuracy: 0.7438 - val_loss: 0.9657 - val_accuracy: 0.6918\n",
      "Epoch 944/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6722 - accuracy: 0.7446 - val_loss: 0.9701 - val_accuracy: 0.6876\n",
      "Epoch 945/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6704 - accuracy: 0.7476 - val_loss: 0.9646 - val_accuracy: 0.6908\n",
      "Epoch 946/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.7397 - val_loss: 0.9866 - val_accuracy: 0.6837\n",
      "Epoch 947/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6758 - accuracy: 0.7437 - val_loss: 0.9719 - val_accuracy: 0.6835\n",
      "Epoch 948/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.7378 - val_loss: 0.9658 - val_accuracy: 0.6824\n",
      "Epoch 949/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6810 - accuracy: 0.7434 - val_loss: 0.9642 - val_accuracy: 0.6903\n",
      "Epoch 950/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6791 - accuracy: 0.7427 - val_loss: 0.9559 - val_accuracy: 0.6889\n",
      "Epoch 951/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 0.6732 - accuracy: 0.7445 - val_loss: 0.9594 - val_accuracy: 0.6862\n",
      "Epoch 952/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6773 - accuracy: 0.7447 - val_loss: 0.9691 - val_accuracy: 0.6846\n",
      "Epoch 953/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6801 - accuracy: 0.7431 - val_loss: 0.9779 - val_accuracy: 0.6829\n",
      "Epoch 954/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6802 - accuracy: 0.7440 - val_loss: 0.9694 - val_accuracy: 0.6867\n",
      "Epoch 955/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6790 - accuracy: 0.7433 - val_loss: 0.9861 - val_accuracy: 0.6799\n",
      "Epoch 956/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6771 - accuracy: 0.7437 - val_loss: 0.9737 - val_accuracy: 0.6881\n",
      "Epoch 957/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6775 - accuracy: 0.7450 - val_loss: 0.9633 - val_accuracy: 0.6936\n",
      "Epoch 958/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6793 - accuracy: 0.7428 - val_loss: 0.9569 - val_accuracy: 0.6936\n",
      "Epoch 959/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6805 - accuracy: 0.7453 - val_loss: 0.9789 - val_accuracy: 0.6837\n",
      "Epoch 960/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.7416 - val_loss: 0.9751 - val_accuracy: 0.6831\n",
      "Epoch 961/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6733 - accuracy: 0.7453 - val_loss: 0.9606 - val_accuracy: 0.6882\n",
      "Epoch 962/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6742 - accuracy: 0.7467 - val_loss: 0.9593 - val_accuracy: 0.6974\n",
      "Epoch 963/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6762 - accuracy: 0.7458 - val_loss: 0.9637 - val_accuracy: 0.6872\n",
      "Epoch 964/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6776 - accuracy: 0.7470 - val_loss: 0.9539 - val_accuracy: 0.6938\n",
      "Epoch 965/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6794 - accuracy: 0.7442 - val_loss: 0.9563 - val_accuracy: 0.6925\n",
      "Epoch 966/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6786 - accuracy: 0.7441 - val_loss: 0.9502 - val_accuracy: 0.6951\n",
      "Epoch 967/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6739 - accuracy: 0.7436 - val_loss: 0.9803 - val_accuracy: 0.6807\n",
      "Epoch 968/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6767 - accuracy: 0.7414 - val_loss: 0.9874 - val_accuracy: 0.6853\n",
      "Epoch 969/1000\n",
      "450/450 [==============================] - 2s 4ms/step - loss: 0.6704 - accuracy: 0.7462 - val_loss: 0.9703 - val_accuracy: 0.6899\n",
      "Epoch 970/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6782 - accuracy: 0.7429 - val_loss: 0.9955 - val_accuracy: 0.6794\n",
      "Epoch 971/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.7451 - val_loss: 0.9651 - val_accuracy: 0.6871\n",
      "Epoch 972/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.7439 - val_loss: 0.9630 - val_accuracy: 0.6947\n",
      "Epoch 973/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6861 - accuracy: 0.7425 - val_loss: 0.9675 - val_accuracy: 0.6846\n",
      "Epoch 974/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6773 - accuracy: 0.7448 - val_loss: 0.9615 - val_accuracy: 0.6907\n",
      "Epoch 975/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6777 - accuracy: 0.7434 - val_loss: 0.9586 - val_accuracy: 0.6896\n",
      "Epoch 976/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6697 - accuracy: 0.7473 - val_loss: 0.9829 - val_accuracy: 0.6811\n",
      "Epoch 977/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6702 - accuracy: 0.7462 - val_loss: 0.9459 - val_accuracy: 0.6956\n",
      "Epoch 978/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6782 - accuracy: 0.7431 - val_loss: 0.9735 - val_accuracy: 0.6865\n",
      "Epoch 979/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6744 - accuracy: 0.7450 - val_loss: 0.9538 - val_accuracy: 0.6951\n",
      "Epoch 980/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6717 - accuracy: 0.7460 - val_loss: 0.9641 - val_accuracy: 0.6915\n",
      "Epoch 981/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6738 - accuracy: 0.7428 - val_loss: 0.9735 - val_accuracy: 0.6858\n",
      "Epoch 982/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.7459 - val_loss: 0.9695 - val_accuracy: 0.6928\n",
      "Epoch 983/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6757 - accuracy: 0.7451 - val_loss: 0.9735 - val_accuracy: 0.6853\n",
      "Epoch 984/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6788 - accuracy: 0.7429 - val_loss: 0.9712 - val_accuracy: 0.6879\n",
      "Epoch 985/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6774 - accuracy: 0.7434 - val_loss: 0.9645 - val_accuracy: 0.6862\n",
      "Epoch 986/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6750 - accuracy: 0.7442 - val_loss: 0.9765 - val_accuracy: 0.6911\n",
      "Epoch 987/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.7452 - val_loss: 0.9678 - val_accuracy: 0.6935\n",
      "Epoch 988/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 0.6774 - accuracy: 0.7419 - val_loss: 0.9645 - val_accuracy: 0.6919\n",
      "Epoch 989/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.7465 - val_loss: 0.9757 - val_accuracy: 0.6844\n",
      "Epoch 990/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6759 - accuracy: 0.7451 - val_loss: 0.9736 - val_accuracy: 0.6840\n",
      "Epoch 991/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6741 - accuracy: 0.7447 - val_loss: 0.9546 - val_accuracy: 0.6950\n",
      "Epoch 992/1000\n",
      "450/450 [==============================] - 2s 3ms/step - loss: 0.6706 - accuracy: 0.7466 - val_loss: 0.9721 - val_accuracy: 0.6958\n",
      "Epoch 993/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.7436 - val_loss: 0.9830 - val_accuracy: 0.6837\n",
      "Epoch 994/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.7420 - val_loss: 0.9634 - val_accuracy: 0.6908\n",
      "Epoch 995/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6770 - accuracy: 0.7464 - val_loss: 0.9669 - val_accuracy: 0.6929\n",
      "Epoch 996/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6718 - accuracy: 0.7453 - val_loss: 0.9697 - val_accuracy: 0.6932\n",
      "Epoch 997/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6741 - accuracy: 0.7466 - val_loss: 0.9827 - val_accuracy: 0.6847\n",
      "Epoch 998/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6778 - accuracy: 0.7430 - val_loss: 0.9640 - val_accuracy: 0.6914\n",
      "Epoch 999/1000\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.6729 - accuracy: 0.7483 - val_loss: 0.9536 - val_accuracy: 0.6976\n",
      "Epoch 1000/1000\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.6702 - accuracy: 0.7464 - val_loss: 0.9841 - val_accuracy: 0.6892\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 2ms/step - loss: 0.9258 - accuracy: 0.7023\n",
      "Test Loss: 0.9257733225822449, Test Accuracy: 0.7023333311080933\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Philipp/opt/anaconda3/envs/projects/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('utils/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the accuracy in order to see whether we have overfitting or stop too early\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "sns.lineplot(\n",
    "    history.history['accuracy'],\n",
    "    ax=ax,\n",
    "    label='accuracy'\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    history.history['val_accuracy'],\n",
    "    ax=ax,\n",
    "    label='validation accuracy'\n",
    ")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of train and test data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on some small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_test_data = (\n",
    "    ('zucker fabrik', 'ft'),\n",
    "    ('Lebensmittel kommssionierung', 'ft'),\n",
    "    ('gelnder biegen', 'mr'),\n",
    "    ('gebudeausrstung technische', 'ct'),\n",
    "    ('krbiskernl softgels', 'ft')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "For word zucker fabrik\n",
      "We predict ch\n",
      "The correct solution is ft\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "For word Lebensmittel kommssionierung\n",
      "We predict ft\n",
      "The correct solution is ft\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "For word gelnder biegen\n",
      "We predict mr\n",
      "The correct solution is mr\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "For word gebudeausrstung technische\n",
      "We predict ct\n",
      "The correct solution is ct\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "For word krbiskernl softgels\n",
      "We predict ct\n",
      "The correct solution is ft\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in tuple_test_data:\n",
    "    word = sample[0]\n",
    "    correct = sample[1]\n",
    "    new_word_embedding = text_to_embeddings(word).reshape(1, -1) \n",
    "\n",
    "    # Predict the label for the embedded word\n",
    "    predicted_probabilities = model.predict(new_word_embedding)\n",
    "    predicted_label_index = predicted_probabilities.argmax(axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_index])\n",
    "\n",
    "    print(f'For word {word}')\n",
    "    print(f'We predict {predicted_label[0]}')\n",
    "    print(f'The correct solution is {correct}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
