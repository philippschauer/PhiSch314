{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 20:36:33.791900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import keras\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "model = keras.models.load_model('model.h5')\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embeddings(text, word2vec_model):\n",
    "    tokens = tokenizer(text)\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in word2vec_model.wv:\n",
    "            embeddings.append(word2vec_model.wv[token])\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0) \n",
    "    else:\n",
    "        return np.zeros(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_test_data = (\n",
    "    ('zucker fabrik', 'ft'),\n",
    "    ('Lebensmittel kommssionierung', 'ft'),\n",
    "    ('geländer biegen', 'mr'),\n",
    "    ('gebäudeausrüstung technische', 'ct'),\n",
    "    ('kürbiskernöl softgels', 'ft')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ft'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_word(word: str):\n",
    "    new_word_embedding = text_to_embeddings(word, word2vec_model).reshape(1, -1) \n",
    "    # Predict the label for the embedded word\n",
    "    predicted_probabilities = model.predict(new_word_embedding)\n",
    "    predicted_label_index = predicted_probabilities.argmax(axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_index])\n",
    "    return predicted_label[0]\n",
    "\n",
    "predict_word(word='Lebensmittel kommssionierung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n",
      "For word 'zucker fabrik'\n",
      "We predict ct\n",
      "The correct solution is ft\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "For word 'Lebensmittel kommssionierung'\n",
      "We predict ft\n",
      "The correct solution is ft\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "For word 'geländer biegen'\n",
      "We predict mr\n",
      "The correct solution is mr\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "For word 'gebäudeausrüstung technische'\n",
      "We predict ch\n",
      "The correct solution is ct\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "For word 'kürbiskernöl softgels'\n",
      "We predict ch\n",
      "The correct solution is ft\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample in tuple_test_data:\n",
    "    word = sample[0]\n",
    "    correct = sample[1]\n",
    "    new_word_embedding = text_to_embeddings(word, word2vec_model).reshape(1, -1) \n",
    "\n",
    "    # Predict the label for the embedded word\n",
    "    predicted_probabilities = model.predict(new_word_embedding)\n",
    "    predicted_label_index = predicted_probabilities.argmax(axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_index])\n",
    "\n",
    "    print(f'For word \\'{word}\\'')\n",
    "    print(f'We predict {predicted_label[0]}')\n",
    "    print(f'The correct solution is {correct}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
